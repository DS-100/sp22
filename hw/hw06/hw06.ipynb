{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42dfcad",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw06.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0986bb14",
   "metadata": {},
   "source": [
    "# Homework 6: Modeling and Analyzing COVID-19 Cases\n",
    "## Probability and Estimators\n",
    "## Due Date: Thursday, March 31, 11:59 PM PDT\n",
    "\n",
    "\n",
    "**Content Warning**\n",
    "\n",
    "This assignment includes an analysis of daily COVID-19 cases by U.S. county through 2021. If you feel uncomfortable with this topic, **please contact your GSI or the instructors.**\n",
    "\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about\n",
    "the homework, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others please **include their names** below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6331eacc",
   "metadata": {},
   "source": [
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d42ba55",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this homework, we will investigate a dataset that contains information about COVID-19 cases in the United States, vaccination rates, and various other metadata that can assist in modeling various aspects of COVID-19.\n",
    "\n",
    "Through this homework assignment, you will demonstrate your experience with:\n",
    "* Bootstrap sampling\n",
    "* Bias-variance tradeoff and decomposition\n",
    "* Biased and unbiased estimators\n",
    "* Multicollinearity in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22645f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown\n",
    "\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e48c53",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 1: Random Variables\n",
    "\n",
    "Question 1 is a written problem and should be submitted as a separate PDF to the Written portal of Gradescope. All other questions in this assignment are submitted as part of this notebook.\n",
    "\n",
    "Question 1 PDF File: https://ds100.org/sp22/hw/hw06/hw06_student.pdf\n",
    "<br>Question 1 Overleaf Template: https://ds100.org/sp22/hw/hw06/hw06_template.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e342f",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 2: Exploratory Data Analysis\n",
    "\n",
    "Let's perform some initial exploratory data analysis to examine and visualize potential trends in a COVID-19 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62887708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "covid_data = pd.read_csv('data/covid_data.csv')\n",
    "covid_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15fa582",
   "metadata": {},
   "source": [
    "The data are at county granularity; each row corresponds to COVID-19 data from a U.S. county. Here are some highlights and data sources:\n",
    "\n",
    "* The first few columns encode county and state data; for example, check out the [FIPS](https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt) numeric encoding for U.S. counties.\n",
    "* The next 600 columns record daily COVID-19 cases in the county for the date range 1/22/2020 to 9/12/2021. COVID-19 case data are from CSSE at Johns Hopkins University [GitHub](https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv).\n",
    "* The next few columns include county populations from [U.S. census data](https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/totals/co-est2020.csv), the latest of which is 2020.\n",
    "* The last 5 columns record mask usage survey data on a 5-point scale from `NEVER` to `ALWAYS`. Data are collected in July 2020 from the New York Times [GitHub](https://github.com/nytimes/covid-19-data/blob/master/mask-use/mask-use-by-county.csv).\n",
    "\n",
    "We can use `covid_data.describe()` to see various statistics about the numerical features of the provided COVID-19 data. Do any particular statistics stand out to you? Which might be useful when modeling?\n",
    "\n",
    "**Note:** This isn't a question (i.e. it's worth no points); this is just food for thought as you start to explore the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f93840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "covid_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d8d884",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2a\n",
    "\n",
    "In this homework, we will use linear regression to predict the number of COVID-19 cases on September 12th, 2021 using linear regression. **per capita** (i.e. the number of COVID-19 cases in a county divided the population of the county). Define a column `'9/12/2021_cpc'` in `covid_data` corresponding to the number of cases per capita on September 12th, 2021. \n",
    "\n",
    "Note that we will **always** use the `'POPESTIMATE2020'` as the population of each county.\n",
    "\n",
    "*Hint*: The number of cases per capita should be the total number of cases in a county divided by the population of the county.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce78efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4760ac79",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eac29d3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2b\n",
    "\n",
    "Assign `mask_data` that has six columns from the original `covid_data` table: the five mask columns and the `9/12/2021_cpc` column.\n",
    "\n",
    "**Note**: You should make a **copy** of these columns using `df.copy()` ([link](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html)).\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "102cb391",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_data = ...\n",
    "mask_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e37db29",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1bf5f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 2c\n",
    "\n",
    "In our first model, we will use county-wise mask usage data to predict the number of COVID-19 cases on September 12th, 2021 (i.e., the column `9/12/2021_cpc`). Create a visualization that shows the pairwise correlation between each combination of columns in `mask_data`. For 2-D visualizations, consider Seaborn's [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html).\n",
    "\n",
    "*Hint*: You should be plotting 36 values corresponding to the pairwise correlations of the six columns in `mask_data`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2c\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d968ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9555923",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 2d\n",
    "\n",
    "(1) Describe the trends and takeaways visible in the visualization of pairwise correlations you plotted in Question 2c.\n",
    "\n",
    "(2) Consider the following linear regression model\n",
    "$$\\hat{y} = \\theta^T x,$$\n",
    "where $\\hat{y}$ is the predicted number of COVID-19 cases per capita on 9/12/2021 and $x$ is the five mask usage features. Comment on the quality of predictions and interpretability of features if we fit this linear model to the data.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2d\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf79486",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cf217d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 3: Creating a Preliminary COVID-19 Model\n",
    "\n",
    "This question will guide you through creating a supervised learning framework that will predict the number of COVID-19 cases per capita given various COVID-19 safety protocols that have been implemented. Then, we will investigate the bias, variance, and observational noise of this framework in the next question.\n",
    "\n",
    "Note that any answer responses without the appropriate work (i.e. code or explanation) will be subject to additional review and will not receive any credit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3cd1a6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3a\n",
    "\n",
    "Train a linear regression model using Scikit-learn, with an intercept term to predict the number of COVID-19 cases per capita for September 12, 2021 using county-wise mask usage data from `mask_data`. Use `train_test_split` to evaluate your model's RMSE on a held-out test set with 33% of the COVID-19 data; call the resulting splits `X_train`, `X_test`, `y_train`, and `y_test`.\n",
    "\n",
    "To pass the autograder, make sure to set the parameter `random_state` to 42 in your call to `train_test_split` to generate a reproducible data split ([documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)).\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "points: 5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14fec8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test sets\n",
    "X = ...\n",
    "y = ...\n",
    "X_train, X_test, y_train, y_test = ..., ..., ..., ...\n",
    "\n",
    "# fit the linear model and make predictions\n",
    "...\n",
    "\n",
    "# compute RMSE on train and test sets\n",
    "train_rmse_cpc = ...\n",
    "test_rmse_cpc = ...\n",
    "\n",
    "...\n",
    "\n",
    "train_rmse_cpc, test_rmse_cpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9128ad87",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2123db06",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3b\n",
    "\n",
    "Visualize the model performance from part (a) by plotting two visualizations: (1) the predictions vs observations on the test set and (2) the residuals for the test set.\n",
    "\n",
    "Some notes:\n",
    "* We've used `plt.subplot` ([documentation](https://matplotlib.org/stable/gallery/subplots_axes_and_figures/subplots_demo.html)) so that you can view both visualizations side-by-side. For example, `plt.subplot(121)` sets the plottable area to the first column of a 1x2 plot grid; you can then call Matplotlib and Seaborn functions to plot that area, before the next `plt.subplot(122)` area is set.\n",
    "* Remember to add a guiding line to both plot where $\\hat{y} = y$, i.e., where the residual is 0.\n",
    "* Remember to label your axes.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d05e75c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))      # do not change this line\n",
    "\n",
    "plt.subplot(121)                # do not change this line\n",
    "# (1) predictions vs observations\n",
    "...\n",
    "\n",
    "plt.subplot(122)               # do not change this line\n",
    "# (2) residual plot\n",
    "...\n",
    "\n",
    "plt.tight_layout()             # do not change this line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c81d15b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3c\n",
    "\n",
    "Describe what the plots in part (b) indicates about this linear model. Justify your answer.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3c\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b8111f",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe802b2c",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 4: Performing Multicollinearity Analysis\n",
    "\n",
    "This question will guide you through performing an analysis that can reveal potential multicollinearity in our features, which is unideal.\n",
    "\n",
    "Note that any answer responses without the appropriate work (i.e. code or math) will be subject to additional review and will not receive any credit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d179ec36",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4a\n",
    "\n",
    "Fill in the blanks below to implement the `bootstrap_sample` function, that returns $k$ randomly drawn samples from a dataset $\\mathcal{D}$ of size $n$ with replacement, each of size $n$ (i.e. same size as the dataset). In other words, the returned object should be a Python list `samples` containing $k$ Pandas DataFrames, each of which have $n$ rows.\n",
    "\n",
    "*Hint*: Take a look at the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) for `df.sample`!\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4a\n",
    "points: 5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc9156a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sample(data, k):\n",
    "    \"\"\"\n",
    "    Performs bootstrap sampling on data to obtain k samples of size n.\n",
    "    \n",
    "    Arguments:\n",
    "        data - Dataset contained as a Pandas DataFrame \n",
    "        k - Number of randomly drawn samples\n",
    "    \n",
    "    Returns:\n",
    "        samples - List containing k Pandas DataFrames of size n each\n",
    "                  corresponding to each sample  \n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    return ...\n",
    "\n",
    "...\n",
    "bootstrap_sample(mask_data, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f19afd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b83211d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4b\n",
    "\n",
    "Using the function from the previous part, generate 1000 bootstrapped samples from the original `mask_data` dataframe. Use Scikit-learn to fit a linear regression model of mask features (with an intercept term) to predict the `9/12/2021_cpc` response. You should fit your model to **each** of the 1000 datasets such that we have 1000 trained models. Make sure to store each of the 1000 trained models in the Python list `models`.\n",
    "\n",
    "Note: You *should not* create any validation or testing sets in this subpart; you should fit your model to the entire resampled dataframe.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4b\n",
    "points: 5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2a1c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "datasets = ...\n",
    "models = []\n",
    "...\n",
    "\n",
    "...\n",
    "\n",
    "# These take up a lot of memory, so we should remove them!\n",
    "del datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28bb88",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb5cb5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4c\n",
    "\n",
    "Fill in the blanks below in the `confidence_interval` function to generate a 95% confidence interval for each of our parameters $\\theta_i$, including an intercept term if applicable. All of the helper code to extract coefficients from our trained models has been implemented for you already.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4c\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96150d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coefs(models, include_intercept = True):\n",
    "    \"\"\"\n",
    "    NOTE: This function has already been implemented. You do not need to modify this!\n",
    "    \n",
    "    Extracts coefficients of all the linear regression models in models, and returns\n",
    "    it as a NumPy array with one model's coefficients as each row.\n",
    "    \n",
    "    Arguments:\n",
    "        models - Contains k sklearn LinearRegression models, each with p + 1 coefficients\n",
    "        include_intercept - Whether to include intercept in returned coefficients\n",
    "    \n",
    "    Returns:\n",
    "        coef_array - Coefficients of all k models, each with p + 1 coefficients (if intercept\n",
    "                     enabled, otherwise p). Returned object is k x (p + 1) NumPy array.\n",
    "    \"\"\"\n",
    "    coef_array = np.zeros(shape = (len(models), len(models[0].coef_) + 1))\n",
    "    for i, m in enumerate(models):\n",
    "        coef_array[i, 0] = m.intercept_\n",
    "        coef_array[i, 1:] = m.coef_\n",
    "    if include_intercept:\n",
    "        return coef_array \n",
    "    return coef_array[:, 1:]\n",
    "\n",
    "def confidence_interval(coefs):\n",
    "    \"\"\"\n",
    "    Calculates confidence intervals for each theta_i based on coefficients of \n",
    "    bootstrapped models. Returns output as a list of confidence intervals.\n",
    "    \n",
    "    Arguments:\n",
    "        coefs - Output of extract_coefs, a k x (p + 1) or k x p NumPy array containing\n",
    "                coefficients of bootstrapped models\n",
    "    \n",
    "    Returns:\n",
    "        cis - Confidence intervals of each parameter theta_i in the form of a \n",
    "              list like this: [(0.5, 0.75), (0.2, 0.4), ...]\n",
    "    \"\"\"\n",
    "    cis = []\n",
    "    \n",
    "    # FILL IN CODE BELOW\n",
    "    for i in range(...):\n",
    "        theta_i_values = ...\n",
    "        theta_i_lower_ci, theta_i_upper_ci = np.percentile(...), np.percentile(...)\n",
    "        cis.append((theta_i_lower_ci, theta_i_upper_ci))\n",
    "    \n",
    "    return cis\n",
    "\n",
    "...\n",
    "\n",
    "# compute confidence intervals\n",
    "model_coefs = extract_coefs(models)\n",
    "cis = confidence_interval(model_coefs)\n",
    "\n",
    "# pretty print in a table\n",
    "display(Markdown('#### Confidence Intervals:'))\n",
    "md_list = [\"|parameter|lower|upper|\",\n",
    "           \"----|----|----|\"]\n",
    "md_list += [fr\"|$\\theta_{i}$|{lci}|{uci}|\" for i, (lci, uci) in enumerate(cis)]\n",
    "display(Markdown('\\n'.join(md_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896b9a21",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a2e81",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 4d\n",
    "\n",
    "Interpret the confidence intervals above for each of the $\\theta_i$, where $\\theta_0$ is the intercept term and the remaining $\\theta_i$ for $i > 0$ are parameters corresponding to mask usage features. What does this indicate about our data and our model?\n",
    "\n",
    "Describe a mathematical reason why this could be happening.\n",
    "\n",
    "*Hint*: Take a look at the design matrix!\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4d\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dab6710",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78069e4a",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 5: Performing Bias-Variance Analysis\n",
    "\n",
    "This question will guide you through performing an analysis that can estimate the bias and variance of our models, which can be helpful in modeling.\n",
    "\n",
    "Note that any answer responses without the appropriate work (i.e. code or explanation) will be subject to additional review and will not receive any credit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20ff1b3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5a\n",
    "\n",
    "We will use the same bootstrapped models contained in the Python list `models` to estimate our **model variance**. To do this, recall that the model variance on a data point is simply the variance of our predictions on that sample point. From the bias-variance decomposition in lecture, for a parametric model $\\hat{Y}(x) = f_{\\hat{\\theta}}(x)$:\n",
    "\n",
    "$$\\text{model variance} = \\mathrm{Var}(f_{\\hat{\\theta}}(x))$$\n",
    "\n",
    "To investigate the variance in our test predictions, we sample a particular data point $(x_i, y_i)$. Define the **model risk** for this point as the mean square error over all possible fitted models:\n",
    "\n",
    "$$\\mathbb{E}\\left[\\left(y_i - f_{\\hat{\\theta}}(x_i)\\right)^2\\right]$$\n",
    "\n",
    "Note that in contrast to lecture, you are considering a particular observation of the random response variable $Y = y_i$. Therefore model risk is an expectation over the estimate $\\hat{\\theta}$, which is a function of the random sample you used to fit your model.\n",
    "\n",
    "Using the bootstrapped estimates `models`, approximate the ratio of model variance to model risk for the datapoint $i = 100$, i.e., $(x_{100}, y_{100})$. You can interpret this ratio as the the proportion of the expected square error on the data point \"captured\" by the model variance. Since you bootstrapped 1000 models, you can generate 1000 predictions for the given $x_i$. Recall that `X` is the design matrix of mask features, and `y` is the `9/12/2021_cpc` response.\n",
    "\n",
    "Assign `prop_var` to the computed, approximate ratio:\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{Var}\\left(f_{\\hat{\\theta}}(x_{100})\\right)}{\\mathbb{E}\\left[\\left(y_{100} - f_{\\hat{\\theta}}(x_{100})\\right)^2\\right]}\n",
    "$$\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5a\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92a0f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_var = ...\n",
    "\n",
    "...\n",
    "prop_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b3425b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b47535c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 5b\n",
    "\n",
    "Comment on the ratio `prop_var`, which is the proportion of the expected square error on the data point captured by the model variance. Is the model variance the dominant term in the bias-variance decomposition? If not, what term(s) dominate the bias-variance decomposition?\n",
    "\n",
    "Justify your answer.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5b\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce8aed4",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96465bc7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 5c\n",
    "\n",
    "Using the bias-variance decomposition above, calculate the average variance and average mean square error across 250 randomly sampled $(x_i, y_i)$ points. In other words, estimate the following quantities across all $x_i$ and $y_i$ in `X_sample` and `y_sample`:\n",
    "\n",
    "$$\n",
    "\\frac{1}{250} \\sum_{i=1}^{250} \\mathrm{Var}\\left(f_{\\hat{\\theta}}(x_i)\\right)\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\frac{1}{250} \\sum_{i=1}^{250} \\mathbb{E}\\left[\\left(y_i - f_{\\hat{\\theta}}(x_i)\\right)^2\\right]\n",
    "$$\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5c\n",
    "points: 3\n",
    "manual: False\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "640ad45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X_sample = X.sample(250)         # generate 250 x_i\n",
    "y_sample = y.loc[X_sample.index] # ...and select the corresponding y_i\n",
    "\n",
    "avg_var, avg_mse = ..., ...\n",
    "...\n",
    "avg_var, avg_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46c1b95",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ec3823",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 5d\n",
    "\n",
    "Propose a solution to reducing the mean square error using the insights gained from the bias-variance decomposition above. Please show all quantities and work that informs your analysis.\n",
    "\n",
    "Assume that the standard bias-variance decomposition used in lecture can be applied here.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5d\n",
    "points: 2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bacede",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad6766",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 6: Improving our Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c889ec0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 6a\n",
    "\n",
    "Suppose we decide to add a feature to our model corresponding to the number of cases per capita the week before (i.e. September 5, 2021). Calculate the cases per capita on September 5, 2021 from the original `covid_data` table, and store it in `mask_data` as a column named `'9/5/2021_cpc'`.\n",
    "\n",
    "*Hint*: This should be similar to Question 2a!\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c26e862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "mask_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fd3cdb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef88b0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 6b\n",
    "\n",
    "Add the feature that we generated in the previous subpart into our design matrix, and train a Scikit-Learn linear regression model **without an intercept term**. Use `train_test_split` to evaluate your model's RMSE on a held-out validation set with 33% of the county-wise data `mask_data`.\n",
    "\n",
    "To pass the autograder, make sure to set the parameter `random_state` to 42 in your call to `train_test_split`.\n",
    "\n",
    "*Hint:* This should be similar to Question 3a!\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6b\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "326e1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test sets\n",
    "X_improved = ...\n",
    "y_improved = ...\n",
    "X_improved_train, X_improved_test, y_improved_train, y_improved_test = ..., ..., ..., ...\n",
    "\n",
    "# fit the linear model and make predictions\n",
    "...\n",
    "\n",
    "# compute RMSE on train and test sets\n",
    "train_rmse_improved_cpc = ...\n",
    "test_rmse_improved_cpc = ...\n",
    "\n",
    "\n",
    "train_rmse_improved_cpc, test_rmse_improved_cpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e11389",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2367e9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6c\n",
    "\n",
    "Compare the RMSE of our improved model with an extra feature with the intercept term removed with the RMSE obtained in the model from Question 3a. \n",
    "\n",
    "Comment on what you would *expect* to happen if you repeated the multicollinearity and bias-variance analyses on this new model using bootstrapping. Specifically, what would you expect to happen with this new model bias? \n",
    "\n",
    "*Hint*: If you wish, you may want to carry out this analysis by adding a cell below this. Please delete it afterwards and note that you *may* run into memory issues if you run it too many times!\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6c\n",
    "points: 2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff61a61f",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abb75bb",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "Closing note: The model you built in Question 6 is called an *autoregressive model*. To understand more about autoregressive models and collinearity, check out [this paper pre-print](https://psyarxiv.com/96snh)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6001ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": []
   },
   "source": [
    "## Congratulations!\n",
    "\n",
    "Congrats! You are finished with this homework assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570d0ca5",
   "metadata": {},
   "source": [
    "## Detailed Submission Instructions\n",
    "\n",
    "**There are two parts to this assignment.**\n",
    "1. Question 1 is a written problem and should be submitted as a separate PDF to the Written portal of Gradescope. Please see the top of this notebook for the question writeup.\n",
    "\n",
    "1. All other questions are submitted as part of this notebook. Please see the following cells to generate the zip file for the Coding portal of Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90471ec8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e008be6d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a996f07a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e3e24",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd38a4",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
