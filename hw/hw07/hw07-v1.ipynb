{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933976e0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw07-v1.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc069739",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "# Homework 7: IMDb and U.S. Presidential Elections\n",
    "## SQL + PCA\n",
    "## Due Date: Thursday, April 14, 11:59 PM PDT\n",
    "\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about\n",
    "the homework, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others please **include their names** below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8cb155",
   "metadata": {},
   "source": [
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938a6903",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This homework has two disjoint parts:\n",
    "\n",
    "**Part 1:** We will use SQL to dive deep into the Internet Movie Database (IMDb) and answer different questions involving movies, actors, and movie ratings. [Click here to jump to Part 1](#part-1).\n",
    "\n",
    "**Part 2:** We will use Principal Component Analysis to understand a high-dimensional dataset: U.S. Presidential Elections by State. [Click here to jump to Part 2](#part-2).\n",
    "\n",
    "## Grading\n",
    "Grading is broken down into autograded answers and free response. For autograded answers, the results of your code are compared to provided and/or hidden tests. For free response, readers will evaluate how well you answered the question and/or fulfilled the requirements of the question.\n",
    "\n",
    "<!--\n",
    "<details>\n",
    "    <summary>[Click to Expand] <b>Scoring Breakdown</b></summary>-->\n",
    "|Question|Points|\n",
    "|---|---|\n",
    "|Q1a | 2 |\n",
    "|Q1b | 2 |\n",
    "|Q2 | 3 |\n",
    "|Q3 | 3 |\n",
    "|Q4 | 4 |\n",
    "|Q5 | 4 |\n",
    "|Q6a | 1 |\n",
    "|Q6b | 1 |\n",
    "|Q6c | 1 |\n",
    "|Q6d | 1 |\n",
    "|Q6e | 2 |\n",
    "|Q7a | 2 |\n",
    "|Q7b | 2 |\n",
    "|Q8a | 1 |\n",
    "|Q8b | 2 |\n",
    "|Q8c | 2 |\n",
    "|Total | 33 |\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f13bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import sqlalchemy\n",
    "from pathlib import Path\n",
    "\n",
    "plt.style.use('fivethirtyeight') # Use plt.style.available to see more styles\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "np.set_printoptions(threshold=5) # avoid printing out big matrices\n",
    "%matplotlib inline\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b4a6fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "---\n",
    "\n",
    "<a id='part-1'></a>\n",
    "# Part 1: The IMDB (mini) Dataset\n",
    "\n",
    "\n",
    "(Click [here](#top) to jump back to the top of this notebook.)\n",
    "\n",
    "We will explore a miniature version of the [IMDb Dataset](https://www.imdb.com/interfaces/). This is the same dataset that we used for this week's lab. The remainder of this overview section is copied from this week's lab.\n",
    "\n",
    "Let's load in the database in two ways (using both Python and cell magic) so that we can flexibly explore the SQL database.\n",
    "\n",
    "A few reminders: \n",
    "* **Only SQL code written with `pd.read_sql` will be graded.**  You should feel free to create `%%sql` cells **after** your Python answer + autograder cells to reduce debugging headaches, but you will still need to copy over any SQL to the Python answer cells. **Do not** add new cells betwen the question and the grading cells; it will cause errors when we run the autograder, and it will sometimes cause an error in generating the PDF file.\n",
    "\n",
    "* **Caution: Be careful with large SQL queries!!** You may need to reboot your Jupyter Hub instance if it stops responding. **Use the LIMIT keyword** to avoid printing out 100k-sized tables (but remember to remove it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b69db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell and the next one\n",
    "engine = sqlalchemy.create_engine(\"sqlite:///data/imdbmini.db\")\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "565f392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql sqlite:///data/imdbmini.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b8d50",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e7deb0",
   "metadata": {},
   "source": [
    "Let's take a look at the table schemas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "551f7109",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- just run this cell --\n",
    "SELECT * FROM sqlite_master WHERE type='table';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a780241c",
   "metadata": {},
   "source": [
    "From running the above cell, we see the database has 4 tables: `Name`, `Role`, `Rating`, and `Title`.\n",
    "\n",
    "<details>\n",
    "    <summary>[<b>Click to Expand</b>] See descriptions of each table's schema.</summary>\n",
    "    \n",
    "**`Name`** – Contains the following information for names of people.\n",
    "    \n",
    "- nconst (text) - alphanumeric unique identifier of the name/person\n",
    "- primaryName (text)– name by which the person is most often credited\n",
    "- birthYear (integer) – in YYYY format\n",
    "- deathYear (integer) – in YYYY format\n",
    "    \n",
    "    \n",
    "**`Role`** – Contains the principal cast/crew for titles.\n",
    "    \n",
    "- tconst (text) - alphanumeric unique identifier of the title\n",
    "- ordering (integer) – a number to uniquely identify rows for a given tconst\n",
    "- nconst (text) - alphanumeric unique identifier of the name/person\n",
    "- category (text) - the category of job that person was in\n",
    "- characters (text) - the name of the character played if applicable, else '\\\\N'\n",
    "    \n",
    "**`Rating`** – Contains the IMDb rating and votes information for titles.\n",
    "    \n",
    "- tconst (integer) - alphanumeric unique identifier of the title\n",
    "- averageRating (text) – weighted average of all the individual user ratings\n",
    "- numVotes (text) - number of votes (i.e., ratings) the title has received\n",
    "    \n",
    "**`Title`** - Contains the following information for titles.\n",
    "    \n",
    "- tconst (text) - alphanumeric unique identifier of the title\n",
    "- titleType (text) -  the type/format of the title\n",
    "- primaryTitle (text) -  the more popular title / the title used by the filmmakers on promotional materials at the point of release\n",
    "- isAdult (text) - 0: non-adult title; 1: adult title\n",
    "- startYear (text) – represents the release year of a title.\n",
    "- runtimeMinutes (integer)  – primary runtime of the title, in minutes\n",
    "    \n",
    "</details>\n",
    "\n",
    "<br/><br/>\n",
    "From the above descriptions, we can conclude the following:\n",
    "* `Name.nconst` and `Title.tconst` are primary keys of the `Name` and `Title` tables, respectively.\n",
    "* `Role.nconst` and `Role.tconst` are **foreign keys** that point to `Name.nconst` and `Title.tconst`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd29b6",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 1\n",
    "\n",
    "### Question 1a\n",
    "How far back does our data go? Does it only include recent data, or do we have information about older movies and movie stars as well? \n",
    "\n",
    "List the **10 oldest films** by `startYear` and then `primaryTitle` both in **ascending** order.  Do not include films where the `startYear` is `NULL`.  The output should contain the `startYear`, `primaryTitle`, and `titleType`.\n",
    "\n",
    "Remember, you can create a `%%sql` cell **after** the grader cell as scratch work. Just be sure to copy the query back into the Python cell to run the autograder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7c68e813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_q1a = \"\"\"\n",
    "...       # replace this with\n",
    "...;      # your multi-line solution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "res_q1a = pd.read_sql(query_q1a, engine)\n",
    "res_q1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de275f8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b044e0",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 1b\n",
    "\n",
    "Next, let's calculate the distribution of films by year. Write a query that returns the **total** films for each `startYear` in the `Title` table as `total`.  Keep in mind that some entries may not have a `startYear` listed -- you should filter those out.  Order your final results by the `startYear` in **ascending** order.\n",
    "\n",
    "The first few records of the table should look like the following (but you should compute the entire table).\n",
    "\n",
    "\n",
    "| |startYear|total|\n",
    "|-----|------|-----|\n",
    "|**0**|1902|1|\n",
    "|**1**|1915|1|\n",
    "|**2**|1920|1|\n",
    "|**3**|1921|1|\n",
    "|**4**|1922|1|\n",
    "|...|...|...|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "94695d48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_q1b = \"\"\"\n",
    "...       # replace this with\n",
    "...;      # your multi-line solution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "res_q1b = pd.read_sql(query_q1b, engine)\n",
    "res_q1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784673f3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd0fa2d",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "The following should generate an interesting plot of the number of films that premiered each year. Notice there is a dip between the 1920s and late 1940s. Why might that be? *This question is rhetorical; you do not need to write your answer anywhere.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11f90a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "px.bar(res_q1b, x=\"startYear\", y=\"total\",\n",
    "       title=\"Number of films premiered each year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d141a",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 2\n",
    "\n",
    "Who are the **top 10 most prolific movie actors**?\n",
    "\n",
    "Define the term \"movie actor\" is defined as anyone with an `actor` or `actress` job category role in a `movie` title.\n",
    "\n",
    "Your SQL query should output exactly two fields named `name` (the movie actor name) and `total` (the number of movies the movie actor appears in). Order the records by `total` in descending order, and break ties by ordering by `name` in ascending order.\n",
    "\n",
    "Your result should look something like the following, but without `????`:\n",
    "\n",
    "| | name | total |\n",
    "|-----|-----|-----|\n",
    "|**0**| ???? | 64 |\n",
    "|**1**| ???? | 54 |\n",
    "|**2**| ???? | 53 |\n",
    "|**3**| ???? | 49 |\n",
    "|**4**| ???? | 46 |\n",
    "|**5**| ???? | 43 |\n",
    "|**6**| ???? | 41 |\n",
    "|**7**| ???? | 40 |\n",
    "|**8**| ???? | 40 |\n",
    "|**9**| ???? | 39 |\n",
    "\n",
    "Some hints: \n",
    "\n",
    "* ***The query should take < 2 minutes to run.***\n",
    "* Google the top of the list and see if it makes sense.\n",
    "* If you want to include a non-aggregate field in the `SELECT` clause, it must also be included in the `GROUP BY` clause.\n",
    "<!--* You can assume each movie actor only has one role per film. If you're not sure how this hint affects your query, ignore this hint.-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b215347b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# query_q2 = \"\"\"\n",
    "# ...       # replace this with\n",
    "# ...;      # your multi-line solution\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "res_q2 = pd.read_sql(query_q2, engine)\n",
    "res_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a44f18",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1df52c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(res_q2['name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b3e29a",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 3: The `CASE` Keyword\n",
    "\n",
    "The `Rating` table has the `numVotes` and the `averageRating` for each title. Which **_movies_** were **\"big hits\"**, defined as a movie with over 100,000 votes? Construct the following table:\n",
    "\n",
    "| | isBigHit | total |\n",
    "|-----|-----|-----|\n",
    "|**0**| no | ???? |\n",
    "|**1**| yes | ???? |\n",
    "\n",
    "Where `????` is replaced with the correct values. The row with `no` should have the count for how many movies **are not** big hits, and the row with `yes` should have the count of how many movies **are** big hits.\n",
    "\n",
    "* Rating.numVotes currently consists of string objects, use `CAST(Rating.numVotes AS int)` to convert them to integer.\n",
    "* You will need to use  some type of `JOIN`.\n",
    "* You may also consider using a `CASE WHEN ... IS ... THEN 'yes' ... ELSE ... END` statement. `CASE` statements are the SQL-equivalent of Python `if... elif... else` statements. To read up on `CASE`, take a look at the following links:\n",
    "    - https://mode.com/sql-tutorial/sql-case/\n",
    "    - https://www.w3schools.com/sql/sql_ref_case.asp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e49aae84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_q3 = \"\"\"\n",
    "...       # replace this with\n",
    "...;      # your multi-line solution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "res_q3 = pd.read_sql(query_q3, engine)\n",
    "res_q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34774ca7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df3f5d9",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 4\n",
    "\n",
    "**How does film length relate to ratings?**  To answer this question we want to bin films by length and compute the average of the average ratings within each length bin. We will group movies by 10-minute increments -- that is, one bin for movies \\[0, 10) minutes long, another for \\[10, 20) minutes, another for \\[20, 30) minutes, and so on. Use the following code snippet to help construct 10-minute bins: \n",
    "\n",
    "```\n",
    "ROUND(runtimeMinutes / 10.0 + 0.5) * 10 AS runtimeBin\n",
    "```\n",
    "\n",
    "Construct a table containing the **`runtimeBin`**, the **average** of the **average ratings** (as `averageRating`), the **average number of votes** (as `averageNumVotes`), and the number of `titles` in that **runtimeBin** (as `total`).  Only include movies with **at least 10000 votes**.  Order the final results by the value of `runtimeBin`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c19df577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_q4 = \"\"\"\n",
    "...       # replace this with\n",
    "...;      # your multi-line solution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "res_q4 = pd.read_sql(query_q4, engine)\n",
    "res_q4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a18ae04",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cc5084",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "If your SQL query is correct you should get some interesting plots below.  This might explain why directors keep going a particular direction with film lengths.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d730d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "px.bar(res_q4, x=\"runtimeBin\", y=\"total\",\n",
    "       title=\"Distribution of Movie Runtimes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffc49027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "px.line(res_q4, x=\"runtimeBin\", y=\"averageRating\",\n",
    "        title=\"Movie Ratings vs. Runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf44a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(res_q4, x=\"runtimeBin\", y=\"averageNumVotes\",\n",
    "        title=\"Movie Number of Votes vs. Runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f1d24",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 5\n",
    "\n",
    "\n",
    "Which **movie actors** have the highest average ratings across all the **movies** in which they star? Again, define \"movie actor\" as anyone with an `actor` or `actress` job category role in a `movie` title.\n",
    "\n",
    "Construct a table consisting of the **movie actor's name**  (as `name`) and their **average actor rating** (as `actorRating`) computed by rescaling ratings for movies in which they had a role:\n",
    "\n",
    "$$\n",
    "\\text{actorRating} = \n",
    "\\frac{\\sum_m \\text{averageRating}[m] * \\text{numVotes}[m]}{\\sum_m \\text{numVotes}[m]}\n",
    "$$\n",
    "\n",
    "Some notes:\n",
    "* Note that if an actor/actress has multiple `role` listings for a film then that film will have a bigger impact in the overall average (this is desired).\n",
    "* ***The query should take < 3 minutes to run.***\n",
    "* Only consider ratings where there are **at least 1000** votes and only consider movie actors that have **at least 20 rated performances**. Present the movie actors with the **top 10** `actorRating` in descending order and break ties alphabetically using the movie actor's name.\n",
    "\n",
    "The results should look something like this but without the `????`, and with higher rating precision.\n",
    "\n",
    "| | name | actorRating |\n",
    "|-----|-----|-----|\n",
    "|**0**|????|8.4413...|\n",
    "|**1**|????|8.2473...|\n",
    "|**2**|????|8.1383...|\n",
    "|**3**|????|8.1339...|\n",
    "|**4**|????|8.0349...|\n",
    "|**5**|????|7.9898...|\n",
    "|**6**|????|7.9464...|\n",
    "|**7**|????|7.9330...|\n",
    "|**8**|????|7.9261...|\n",
    "|**9**|????|7.8668...|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2db8d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_q5 = \"\"\"\n",
    "...       # replace this with\n",
    "...;      # your multi-line solution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "res_q5 = pd.read_sql(query_q5, engine)\n",
    "res_q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477c8a8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880af7e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "---\n",
    "\n",
    "<a id='part-2'></a>\n",
    "# Part 2: U.S. Presidential Elections By State\n",
    "\n",
    "(Click [here](#top) to jump back to the top of this notebook.)\n",
    "\n",
    "The second part of this homework focuses on a new dataset. If you haven't worked with Principal Component Analysis before, we highly encourage you to take a look at the PCA lab first. PCA really shines on data where you have reason to believe that the data is relatively low in rank. \n",
    "\n",
    "We'll look at how states voted in presidential elections between 1972 and 2016. **Our ultimate goal in this part is to show how 2D PCA scatterplots can allow us to identify clusters in a high dimensional dataset.** For this example, that means finding groups of states that vote similarly by plotting their 1st and 2nd principal components.\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 6\n",
    "\n",
    "We explore a dataset on U.S. Presidential Elections by State since 1789, as taken from [Wikipedia](https://en.wikipedia.org/wiki/List_of_United_States_presidential_election_results_by_state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a460eeab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/presidential_elections.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d503a170",
   "metadata": {},
   "source": [
    "The data in this table is pretty messy (missing records, inconsistent field naming, etc.), so let's create a clean version.\n",
    "\n",
    "Running the cell below will produce a clean table, which contains exactly 51 rows (corresponding to the 50 states plus Washington DC) and 13 columns (one for each of the election years from 1972 to 2020). The index of this dataframe is the state name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab87a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "df_clean = ( \n",
    "        df.iloc[:, -15:]    \n",
    "        .drop(['Unnamed: 60'], axis = 1) \n",
    "        .rename(columns = {\"2000 ‡\": \"2000\", \"2016 ‡\": \"2016\", \"State.1\": \"State\"}) \n",
    "        .drop([51]) \n",
    "        .set_index(\"State\")\n",
    ")\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec09780",
   "metadata": {},
   "source": [
    "Side note: We produced the data cleaning function chain above by inspecting the CSV file. In your personal projects, you may be tempted to use Excel or Google Sheets (What You See Is What You Get, or WYSIWYG) to clean data. While sometimes more convenient, the downside of this is that you have no record of what you did—and if you have to redownload the data, you have to redo the manual data cleaning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb40ed28",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 6a\n",
    "\n",
    "What does each row in `df_clean` represent?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86356a5",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9011c9a",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 6b\n",
    "\n",
    "To perform PCA, we need to convert our data into numerical values. Create a `df_numerical` dataframe that replaces all of the \"D\" characters in `df_clean` with the number 0, and all of the \"R\" characters with the number 1. \n",
    "\n",
    "*Hint:* Use `df.replace` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7923c50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_numerical = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cdea1e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d315a03",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 6c\n",
    "\n",
    "Now **standardize the data**: Center the data so that each column's mean is 0, and scale the data so that each column's variance is 1. Store your result in `df_standardized`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2fca9d81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_standardized = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6126e2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f911d9",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "We now have our data in a nice and tidy centered and scaled format. Phew! We are now ready to do PCA.\n",
    "\n",
    "<br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 6d: SVD\n",
    "\n",
    "In the following cell, compute the SVD of `df_standardized`:\n",
    "\n",
    "$$\\texttt{df}\\_\\texttt{standardized}=U\\Sigma V^{T}$$\n",
    "\n",
    "\n",
    "Store the $U$, $\\Sigma$, and $V^T$ matrices in `u`, `s`, and `vt` respectively. This is one line of simple code (exactly like what we saw in lecture and what you did in lab) using the [`np.linalg.svd`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html) function with the `full_matrices` argument set to `False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a9d142b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "u, s, vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e87f2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9111c4",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 6e: Get Principal Components\n",
    "\n",
    "Using your results from the previous part, create a new `first_2_pcs` **dataframe** ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)) that contains exactly the first two columns of the principal components matrix. The first column should be labeled `pc1` and the second column should be labeled `pc2`. Store your result in `first_2_pcs`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d34d9fc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_2_pcs = ...\n",
    "first_2_pcs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c2c69",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7c151a",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 7\n",
    "\n",
    "The cell below plots the 1st and 2nd principal components of our 50 states + Washington DC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e64c451e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "sns.scatterplot(data = first_2_pcs, x = \"pc1\", y = \"pc2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a35e16e",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Unfortunately, we have two problems:\n",
    "\n",
    "1. There is a lot of overplotting, with only 28 distinct dots (out of 104 points). This means that at least some states voted exactly alike in these elections.\n",
    "2. We don't know which state is which because the points are unlabeled.\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 7a: Jitter\n",
    "\n",
    "Let's start by addressing problem 1. \n",
    "\n",
    "**In the cell below, create a new dataframe `first_2_pcs_jittered` with a small amount of random noise added to each principal component. In this same cell, create a scatterplot.**\n",
    "\n",
    "To reduce overplotting, we **jitter** the first two principal components:\n",
    "* Add a small amount of random, unbiased Gaussian noise to each value using `np.random.normal` ([documentation](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html)) with mean 0 and standard deviation less than 1.\n",
    "* Don't get caught up on the exact details of your noise generation; it's fine as long as your plot looks roughly the same as the original scatterplot, but without overplotting.\n",
    "* The amount of noise you add *should not significantly affect* the appearance of the plot; it should simply serve to separate overlapping observations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ae33b0d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first, jitter the data\n",
    "first_2_pcs_jittered = ...\n",
    "\n",
    "# then, create a scatter plot\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487df0a5",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8adf8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_2_pcs_jittered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba06047",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 7b\n",
    "\n",
    "To address Problem 2, we can turn to Plotly. The below cell uses these Plotly guides ([example 1](https://plot.ly/python/text-and-annotations/), [example 2](https://plotly.com/python/hover-text-and-formatting/#disabling-or-customizing-hover-of-columns-in-plotly-express)) to create a scatter plot of the jittered ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dd0b09a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "import plotly.express as px\n",
    "\n",
    "# get the state names from the standardized dataframe's index\n",
    "first_2_pcs_jittered['state'] = df_standardized.index\n",
    "\n",
    "# show state names on hover\n",
    "fig = px.scatter(first_2_pcs_jittered, x=\"pc1\", y=\"pc2\",\n",
    "                hover_data={\"state\": True}); \n",
    "\n",
    "fig.show(); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb3481e",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Analyze the above plot. In the below cell, address the following two points:\n",
    "1. Give an example of a cluster of states that vote a similar way. Does the composition of this cluster surprise you? If you're not familiar with U.S. politics, it's fine to just say \"No, I'm not surprised because I don't know anything about U.S. politics.\"\n",
    "1. Include anything interesting that you observe. You will get credit for this as long as you write something reasonable that you can takeaway from the plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0a153e",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239d90c2",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 8\n",
    "\n",
    "We can also look at the contributions of each year's elections results on the values for our principal components.\n",
    "\n",
    "Below, we define the `plot_pc` function that plots and labels the rows of $V^T$. We then call this function to plot the 1st row of $V^T$, i.e., the row of $V^T$ that corresponds to `pc1`.\n",
    "\n",
    "**Note**: If you get an error when running this cell, make sure you are properly assigning the `vt` variable from Question 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "378195be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "\n",
    "def plot_pc(col_names, row_mat_vt, k):\n",
    "    plt.bar(col_names, row_mat_vt[k, :], alpha=0.7)\n",
    "    plt.xticks(col_names, rotation=90);\n",
    "    \n",
    "plt.figure(figsize=(12, 4)) # adjusts size of plot\n",
    "plot_pc(list(df_standardized.columns), vt, 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5435c5",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 8a\n",
    "\n",
    "In the cell below, plot the the 2nd row of $V^T$, i.e., the row of $V^T$ that correpsonds to `pc2`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9205c4bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c04332",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 8b\n",
    "\n",
    "Using the two above plots of the rows of $V^T$ as well as the original table, give a description of what it means for a point to be in the top-right quadrant of the 2-D scatter plot from Question 7.\n",
    "\n",
    "In other words, what is generally true about a state with relatively large positive value for `pc1` (right side of 2-D scatter plot)? For a large positive value for `pc2` (top side of 2-D scatter plot)?\n",
    "\n",
    "Notes:\n",
    "* `pc2` is pretty hard to interpret, and the staff doesn't really have a consensus on what it means either. We'll be nice when grading. \n",
    "* Principal components beyond the first are often hard to interpret (but not always; see the lab).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acc908a",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb7d5bd",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2326f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to use this cell for scratch work. If you need more scratch space, add cells *below* this one.\n",
    "\n",
    "# Make sure to put your actual answer in the cell above where it says \"Type your answer here, replacing this text\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aec391e",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 8c\n",
    "\n",
    "To get a better sense of whether our 2D scatterplot captures the whole story, create a **scree plot** for this data. In other words, plot the fraction of the total variance (y-axis) captured by the ith principal component (x-axis).\n",
    "\n",
    "*Hint:* Be sure to label your axes appropriately! You may find `plt.xticks()` ([documentation](https://matplotlib.org/3.5.0/api/_as_gen/matplotlib.pyplot.xticks.html)) helpful for formatting. Also check out the lab for more on scree plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "804dfe0b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47461514",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "From your scree plot above, you should see that the first two principal components capture a large portion of the variance in our cleaned data. It is partially for this reason that the 2D scatter plot of principal components was easy to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c2339b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": []
   },
   "source": [
    "## Congratulations!\n",
    "\n",
    "Congrats! You are finished with this homework assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cf6ef6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f199e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183db3c0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292280e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b745ba",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "otter": {
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_q1a.shape == (10, 3)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(res_q1a.columns) == set(['startYear', 'primaryTitle', 'titleType'])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_q1b.shape == (103, 2) or res_q1b.shape == (102, 2)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_q2.shape == (10, 2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(res_q2.columns) == set(['name', 'total'])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_q3.shape == (2, 2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(res_q3.columns) == set(['isBigHit', 'total'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(res_q3['isBigHit']) == set(['yes', 'no'])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_q4.shape == (26, 4)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(res_q4.columns) == set(['runtimeBin', 'averageRating', 'averageNumVotes', 'total'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> res_q4[\"runtimeBin\"].min() == 50.0\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> res_q4[\"runtimeBin\"].max() == 370.0\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_q5.shape == (10, 2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(res_q5.columns) == set(['name', 'actorRating'])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6b": {
     "name": "q6b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.all(df_numerical.applymap(lambda x: x in [0, 1]))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> df_numerical['1972']['Alabama'] == 1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6c": {
     "name": "q6c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> all(np.isclose(np.mean(df_standardized), [0] * df_standardized.shape[1]))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(np.isclose(np.var(df_standardized), [1] * df_standardized.shape[1]))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6d": {
     "name": "q6d",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> all(np.isclose([sum(u[:, i] ** 2) for i in range(u.shape[1])], np.ones((u.shape[1],))))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(np.isclose([sum(vt[i, :] ** 2) for i in range(vt.shape[1])], np.ones((u.shape[1],))))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> len(s) == 13\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> (np.isclose(u @ np.diag(s) @ vt, df_standardized)).all()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6e": {
     "name": "q6e",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> first_2_pcs.shape == (51, 2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(first_2_pcs.columns == ['pc1', 'pc2'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(np.isclose(first_2_pcs.loc[0], [-2.9386, 0.7964], atol=1e-4))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(np.isclose(first_2_pcs.loc[46], [-0.2960, -1.5452], atol=1e-4))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(np.isclose(first_2_pcs.loc[28], [0.9442, -1.5338], atol=1e-4))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
