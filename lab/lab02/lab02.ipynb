{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab02.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "title-cell",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Lab 2: Pandas Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To receive credit for a lab, answer all questions correctly and submit before the deadline.\n",
    "\n",
    "**This lab is due  Tuesday, Feb 1st at 11:59 PM.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Walk-Through\n",
    "\n",
    "In addition to the lab notebook, we have also released a prerecorded walk-through video of the lab. We encourage you to reference this video as you work through the lab. Run the cell below to display the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"MLUNk_D7KW0\", list = 'PLQCcNQgUcDfoWO3WVtznI7CBJmtNUqbAN', listType = 'playlist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** below. (That's a good way to learn your classmates' names.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "outline-cell",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "[Pandas](https://pandas.pydata.org/) is one of the most widely used Python libraries in data science. In this lab, you will review commonly used data wrangling operations/tools in Pandas. We aim to give you familiarity with:\n",
    "\n",
    "* Creating DataFrames\n",
    "* Slicing DataFrames (i.e. selecting rows and columns)\n",
    "* Filtering data (using boolean arrays and groupby.filter)\n",
    "* Aggregating (using groupby.agg)\n",
    "\n",
    "In this lab you are going to use several pandas methods. Reminder from lecture that you may press `shift+tab` on method parameters to see the documentation for that method. For example, if you were using the `drop` method in pandas, you couold press shift+tab to see what `drop` is expecting.\n",
    "\n",
    "Pandas is very similar to the datascience library that you saw in Data 8. This [conversion notebook](https://github.com/data-8/materials-x19/blob/master/reference/Datascience%20to%20Pandas%20Conversion%20Notebook.ipynb) may serve as a useful guide!\n",
    "\n",
    "This lab expects that you have watched the pandas lectures. If you have not, this lab will probably take a very long time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-03ce8b2a12c5589d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Note**: The Pandas interface is notoriously confusing for beginners, and the documentation is not consistently great. Throughout the semester, you will have to search through Pandas documentation and experiment, but remember it is part of the learning experience and will help shape you as a data scientist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "basic_intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Creating DataFrames & Basic Manipulations\n",
    "\n",
    "Recall that a [DataFrame](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#dataframe) is a table in which each column has a specific data type; there is an index over the columns (typically string labels) and an index over the rows (typically ordinal numbers).\n",
    "\n",
    "Usually you'll create DataFrames by using a function like `pd.read_csv`. However, in this section, we'll discuss how to create them from scratch.\n",
    "\n",
    "The [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) for the pandas `DataFrame` class provides several constructors for the DataFrame class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "basic_method1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Syntax 1:** You can create a DataFrame by specifying the columns and values using a dictionary as shown below. \n",
    "\n",
    "The keys of the dictionary are the column names, and the values of the dictionary are lists containing the row entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "basic_method1_code",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "fruit_info = pd.DataFrame(\n",
    "    data = {'fruit': ['apple', 'orange', 'banana', 'raspberry'],\n",
    "          'color': ['red', 'orange', 'yellow', 'pink'],\n",
    "          'price': [1.0, 0.75, 0.35, 0.05]\n",
    "          })\n",
    "fruit_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "basic_method2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Syntax 2:** You can also define a DataFrame by specifying the rows as shown below. \n",
    "\n",
    "Each row corresponds to a distinct tuple, and the columns are specified separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "basic_method2_code",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "fruit_info2 = pd.DataFrame(\n",
    "    [(\"red\", \"apple\", 1.0), (\"orange\", \"orange\", 0.75), (\"yellow\", \"banana\", 0.35),\n",
    "     (\"pink\", \"raspberry\", 0.05)], \n",
    "    columns = [\"color\", \"fruit\", \"price\"])\n",
    "fruit_info2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "basic_shape",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "You can obtain the dimensions of a DataFrame by using the shape attribute `DataFrame.shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "basic_shape_code",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "fruit_info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also convert the entire DataFrame into a two-dimensional NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_info.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other constructors but we do not discuss them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REVIEW: Selecting Rows and Columns in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you've seen in lecture and discussion, there are two verbose operators in Python for selecting rows: `loc` and `iloc`. Let's review them briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 1: `loc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first of the two verbose operators is `loc`, which takes two arguments. The first is one or more row **labels**, the second is one or more column **labels**.\n",
    "\n",
    "The desired rows or columns can be provided individually, in slice notation, or as a list. Some examples are given below.\n",
    "\n",
    "Note that **slicing in `loc` is inclusive** on the provided labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rows 0 through 2 and columns fruit through price\n",
    "fruit_info.loc[0:2, 'fruit':'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rows 0 through 2 and columns fruit and price. \n",
    "# Note the difference in notation and result from the previous example.\n",
    "fruit_info.loc[0:2, ['fruit', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rows 0 and 2 and columns fruit and price. \n",
    "fruit_info.loc[[0, 2], ['fruit', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rows 0 and 2 and column fruit\n",
    "fruit_info.loc[[0, 2], ['fruit']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we request a single column but don't enclose it in a list, the return type of the `loc` operator is a `Series` rather than a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get rows 0 and 2 and column fruit, returning the result as a Series\n",
    "fruit_info.loc[[0, 2], 'fruit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we provide only one argument to `loc`, it uses the provided argument to select rows, and returns all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fruit_info.loc[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you try to access columns without providing rows, `loc` will crash. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment, this code will crash\n",
    "#fruit_info.loc[[\"fruit\", \"price\"]]\n",
    "\n",
    "# uncomment, this code works fine: \n",
    "#fruit_info.loc[:, [\"fruit\", \"price\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 2: `iloc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iloc` is very similar to `loc` except that its arguments are row numbers and column numbers, rather than row labels and labels names. A usueful mnemonic is that the `i` stands for \"integer\".\n",
    "\n",
    "In addition, **slicing for `iloc` is exclusive** on the provided integer indices. Some examples are given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get rows 0 through 3 (exclusive) and columns 0 through 2 (exclusive)\n",
    "fruit_info.iloc[0:3, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rows 0 through 3 (exclusive) and columns 0 and 2.\n",
    "fruit_info.iloc[0:3, [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get rows 0 and 2 and columns 0 and 2.\n",
    "fruit_info.iloc[[0, 2], [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rows 0 and 2 and column fruit\n",
    "fruit_info.iloc[[0, 2], [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get rows 0 and 2 and column fruit\n",
    "fruit_info.iloc[[0, 2], 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in these loc and iloc examples above, the row **label** and row **number** were always the same.\n",
    "\n",
    "Let's see an example where they are different. If we sort our fruits by color, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_info_sorted = fruit_info.sort_values(\"price\")\n",
    "fruit_info_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the row number 0 now has index 3, row number 1 now has index 2, etc. These indices are the arbitrary numerical index generated when we created the DataFrame. For example, banana was originally in row 2, and so it has row label 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we request the rows in positions 0 and 2 using `iloc`, we're indexing using the row NUMBERS, not labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_info_sorted.iloc[[0, 2], 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, similar to with `loc`, the second argument to `iloc` is optional. That is, if you provide only one argument to `iloc`, it treats the argument you provide as a set of desired row numbers, not column numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_info.iloc[[0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 3: `[]` Notation for Accessing Rows and Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also supports a bare `[]` operator. It's similar to `loc` in that it lets you access rows and columns by their name.\n",
    "\n",
    "However, unlike `loc`, which takes row names and also optionally column names, `[]` is more flexible. If you provde it only row names, it'll give you rows (same behavior as `loc`), and if you provide it with only column names, it'll give you columns (whereas `loc` will crash).\n",
    "\n",
    "Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_info[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we're providing a list of fruits as single argument to []\n",
    "fruit_info[[\"fruit\", \"color\", \"price\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that slicing notation is not supported for columns if you use `[]` notation. Use `loc` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and this code crashes\n",
    "#fruit_info[\"fruit\":\"price\"]\n",
    "\n",
    "# uncomment and this works fine\n",
    "#fruit_info.loc[:, \"fruit\":\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[]` and `loc` are quite similar. For example, the following two pieces of code are functionally equivalent for selecting the fruit and price columns.\n",
    "\n",
    "1. `fruit_info[[\"fruit\", \"price\"]]` \n",
    "2. `fruit_info.loc[:, [\"fruit\", \"price\"]]`.\n",
    "\n",
    "Because it yields more concise code, you'll find that our code and your code both tend to feature `[]`. However, there are some subtle pitfalls of using `[]`. If you're ever having performance issues, weird behavior, or you see a `SettingWithCopyWarning` in pandas, switch from `[]` to `loc` and this may help.\n",
    "\n",
    "To avoid getting too bogged down in indexing syntax, we'll avoid a more thorough discussion of `[]` and `loc`. We may return to this at a later point in the course.\n",
    "\n",
    "For more on `[]` vs `loc`, you may optionally try reading:\n",
    "1. https://stackoverflow.com/questions/48409128/what-is-the-difference-between-using-loc-and-using-just-square-brackets-to-filte\n",
    "2. https://stackoverflow.com/questions/38886080/python-pandas-series-why-use-loc/65875826#65875826\n",
    "3. https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas/53954986#53954986"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've reviewed basic indexing, let's discuss how we can modify dataframes. We'll do this via a series of exercises. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1(a)\n",
    "\n",
    "For a DataFrame `d`, you can add a column with `d['new column name'] = ...` and assign a list or array of values to the column. Add a column of integers containing 1, 2, 3, and 4 called `rank1` to the `fruit_info` table which expresses your personal preference about the taste ordering for each fruit (1 is tastiest; 4 is least tasty). \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1_answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "fruit_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1(b)\n",
    "\n",
    "You can also add a column to `d` with `d.loc[:, 'new column name'] = ...`. As above, the first parameter is for the rows and second is for columns. The `:` means change all rows and the `'new column name'` indicates the name of the column you are modifying (or in this case, adding). \n",
    "\n",
    "Add a column called `rank2` to the `fruit_info` table which contains the same values in the same order as the `rank1` column.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ef625b2f6154e9b2",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "...\n",
    "fruit_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Use the `.drop()` method to [drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html) both the `rank1` and `rank2` columns you created. Make sure to use the `axis` parameter correctly. Note that `drop` does not change a table, but instead returns a new table with fewer columns or rows unless you set the optional `inplace` parameter.\n",
    "\n",
    "*Hint*: Look through the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) to see how you can drop multiple columns of a Pandas DataFrame at once using a list of column names.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fruit_info_original = ...\n",
    "fruit_info_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 3\n",
    "\n",
    "Use the `.rename()` method to [rename](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html) the columns of `fruit_info_original` so they begin with capital letters. Set this new DataFrame to `fruit_info_caps`. For an example of how to use rename, see the linked documentation above.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "fruit_info_caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "babyname_dataset",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Babynames Dataset\n",
    "For the new few questions of this lab, let's move on to a real world dataset. We'll be using the babynames dataset from Lecture 1. The babynames dataset contains a record of the given names of babies born in the United States each year.\n",
    "\n",
    "First let's run the following cells to build the DataFrame `baby_names`.\n",
    "The cells below download the data from the web and extract the data into a DataFrame. There should be a total of 6215834 records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "fetch_and_cache",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### `fetch_and_cache` Helper\n",
    "\n",
    "The following function downloads and caches data in the `data/` directory and returns the `Path` to the downloaded file. The cell below the function describes how it works. You are not expected to understand this code, but you may find it useful as a reference as a practitioner of data science after the course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "fetch_and_cache_code",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "def fetch_and_cache(data_url, file, data_dir=\"data\", force=False):\n",
    "    \"\"\"\n",
    "    Download and cache a url and return the file object.\n",
    "    \n",
    "    data_url: the web address to download\n",
    "    file: the file in which to save the results.\n",
    "    data_dir: (default=\"data\") the location to save the data\n",
    "    force: if true the file is always re-downloaded \n",
    "    \n",
    "    return: The pathlib.Path to the file.\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    file_path = data_dir/Path(file)\n",
    "    if force and file_path.exists():\n",
    "        file_path.unlink()\n",
    "    if force or not file_path.exists():\n",
    "        print('Downloading...', end=' ')\n",
    "        resp = requests.get(data_url)\n",
    "        with file_path.open('wb') as f:\n",
    "            f.write(resp.content)\n",
    "        print('Done!')\n",
    "    else:\n",
    "        import time \n",
    "        created = time.ctime(file_path.stat().st_ctime)\n",
    "        print(\"Using cached version downloaded at\", created)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-18d54d536c23da04",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "In Python, a `Path` object represents the filesystem paths to files (and other resources). The `pathlib` module is effective for writing code that works on different operating systems and filesystems. \n",
    "\n",
    "To check if a file exists at a path, use `.exists()`. To create a directory for a path, use `.mkdir()`. To remove a file that might be a [symbolic link](https://en.wikipedia.org/wiki/Symbolic_link), use `.unlink()`. \n",
    "\n",
    "This function creates a path to a directory that will contain data files. It ensures that the directory exists (which is required to write files in that directory), then proceeds to download the file based on its URL.\n",
    "\n",
    "The benefit of this function is that not only can you force when you want a new file to be downloaded using the `force` parameter, but in cases when you don't need the file to be re-downloaded, you can use the cached version and save download time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "download_data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Below we use `fetch_and_cache` to download the `namesbystate.zip` zip file, which is a compressed directory of CSV files. \n",
    "\n",
    "**This might take a little while! Consider stretching.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "download_data_code",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data_url = 'https://www.ssa.gov/oact/babynames/state/namesbystate.zip'\n",
    "namesbystate_path = fetch_and_cache(data_url, 'namesbystate.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "build_df",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The following cell builds the final full `baby_names` DataFrame. It first builds one DataFrame per state, because that's how the data are stored in the zip file. Here is documentation for [pd.concat](https://pandas.pydata.org/pandas-docs/version/1.2/reference/api/pandas.concat.html) if you want to know more about its functionality. As before, you are not expected to understand this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "build_df_code",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zf = zipfile.ZipFile(namesbystate_path, 'r')\n",
    "\n",
    "column_labels = ['State', 'Sex', 'Year', 'Name', 'Count']\n",
    "\n",
    "def load_dataframe_from_zip(zf, f):\n",
    "    with zf.open(f) as fh: \n",
    "        return pd.read_csv(fh, header=None, names=column_labels)\n",
    "\n",
    "states = [\n",
    "    load_dataframe_from_zip(zf, f)\n",
    "    for f in sorted(zf.filelist, key=lambda x:x.filename) \n",
    "    if f.filename.endswith('.TXT')\n",
    "]\n",
    "\n",
    "baby_names = states[0]\n",
    "for state_df in states[1:]:\n",
    "    baby_names = pd.concat([baby_names, state_df])\n",
    "baby_names = baby_names.reset_index().iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "build_df_check_len",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "len(baby_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baby_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "slicing_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Selection Examples on Baby Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with our synthetic fruit dataset, we can use `loc` and `iloc` to select rows and columns of interest from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "slicing_e1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "baby_names.loc[2:5, 'Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference between the following cell and the previous one, just passing in `'Name'` returns a Series while `['Name']` returns a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "slicing_e2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "baby_names.loc[2:5, ['Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below collects the rows in positions 1 through 3, and the column in position 3 (\"Name\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1292533181dbd2eb",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "baby_names.iloc[1:4, [3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Use `.loc` to select `Name` and `Year` **in that order** from the `baby_names` table.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4_answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "name_and_year = ...\n",
    "name_and_year[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat the same selection using the plain `[]` notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_and_year = ...\n",
    "name_and_year[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "filter_data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Filtering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "filter_data_op",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Review: Filtering with boolean arrays\n",
    "\n",
    "Filtering is the process of removing unwanted material.  In your quest for cleaner data, you will undoubtedly filter your data at some point: whether it be for clearing up cases with missing values, for culling out fishy outliers, or for analyzing subgroups of your data set.  Example usage looks like `df[df['column name'] < 5]`.\n",
    "\n",
    "For your reference, some commonly used comparison operators are given below.\n",
    "\n",
    "Symbol | Usage      | Meaning \n",
    "------ | ---------- | -------------------------------------\n",
    "==   | a == b   | Does a equal b?\n",
    "<=   | a <= b   | Is a less than or equal to b?\n",
    "&gt;=   | a >= b   | Is a greater than or equal to b?\n",
    "<    | a < b    | Is a less than b?\n",
    "&#62;    | a &#62; b    | Is a greater than b?\n",
    "~    | ~p       | Returns negation of p\n",
    "&#124; | p &#124; q | p OR q\n",
    "&    | p & q    | p AND q\n",
    "^  | p ^ q | p XOR q (exclusive or)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "filter_ca",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "In the following we construct the DataFrame containing only names registered in California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "filter_ca_code",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ca = baby_names[baby_names['State'] == 'CA']\n",
    "ca.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q5a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5\n",
    "Using a boolean array, select the names in Year 2000 (from `baby_names`) that have larger than 3000 counts. Keep all columns from the original `baby_names` DataFrame.\n",
    "\n",
    "Note: Note that compound expressions have to be grouped with parentheses. That is, any time you use `p & q` to filter the DataFrame, make sure to use `df[(df[p]) & (df[q])]` or `df.loc[(df[p]) & (df[q])]`. \n",
    "\n",
    "You may use either `[]` or `loc`. Both will achieve the same result. For more on `[]` vs. `loc` see the stack overflow links from the intro portion of this lab.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q5a_answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "result = ...\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that pandas also has a query command. For example, we can get California baby names with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = baby_names.query('State == \"CA\"')\n",
    "ca.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `query` command, select the names in Year 2000 (from `baby_names`) that have larger than 3000 counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_using_query = ...\n",
    "result_using_query.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-189595bbb3fcaa8e",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Groupby\n",
    "\n",
    "Let's now turn to using groupby from lecture 4.\n",
    "\n",
    "**Note:** This [slide](https://docs.google.com/presentation/d/1FC-cs5MTGSkDzI_7R_ZENgwoHQ4aVamxFOpJuWT0fo0/edit#slide=id.g477ed0f02e_0_390) provides a visual picture of how `groupby.agg` works if you'd like a reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Elections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review**: Let's start by reading in the election dataset from the pandas lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:15.205576Z",
     "start_time": "2020-09-16T20:55:15.194080Z"
    }
   },
   "outputs": [],
   "source": [
    "# run this cell\n",
    "elections = pd.read_csv(\"data/elections.csv\")\n",
    "elections.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw, we can groupby a specific column, e.g. \"Party\". It turns out that using some syntax we didn't cover in lecture, we can print out the subframes that result. This isn't something you'll do for any practical purpose. However, it may help you get an understanding of what groupby is actually doing.\n",
    "\n",
    "An example is given below for elections since 1980."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:16.136582Z",
     "start_time": "2020-09-16T20:55:16.020654Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run this cell\n",
    "for n, g in elections.query(\"Year >= 1980\").groupby(\"Party\"):\n",
    "    print(f\"Name: {n}\") # by the way this is an \"f string\", a relatively new and great feature of Python\n",
    "    display(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that once we've formed groups, we can aggregate each sub-dataframe (a.k.a. group) into a single row using an aggregation function. For example, if we use `.agg(np.mean)` on the groups above, we get back a single DataFrame where each group has been replaced by a single row. In each column for that aggregate row, the value that appears is the average of all values in that group.\n",
    "\n",
    "For columns which are non-numeric, e.g. \"Result\", the column is dropped because we cannot compute the mean of the Result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections.query(\"Year >= 1980\").groupby(\"Party\").agg(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently we can use one of the shorthand aggregation functions, e.g. `.mean()`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "elections.query(\"Year >= 1980\").groupby(\"Party\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the index of the dataframe returned by an `groupby.agg` call is no longer a set of numeric indices from 0 to N-1. Instead, we see that the index for the example above is now the `Party`. If we want to restore our DataFrame so that `Party` is a column rather than the index, we can use `reset_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections.query(\"Year >= 1980\").groupby(\"Party\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE:** Notice that the code above consists of a series of chained method calls. This sort of code is very very common in Pandas programming and in data science in general. Such chained method calls can sometimes go many layers deep, in which case you might consider adding newlines between lines of code for clarity. For example, we could instead write the code above as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas method chaining\n",
    "(\n",
    "elections.query(\"Year >= 1980\").groupby(\"Party\") \n",
    "                               .mean()            ## computes the mean values by party\n",
    "                               .reset_index()     ## reset to a numerical index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I've surrounded the entire call by a big set of parentheses so that Python doesn't complain about the indentation. An alternative is to use the \\ symbol to indicate to Python that your code continues on to the next line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pandas method chaining (alternative)\n",
    "elections.query(\"Year >= 1980\").groupby(\"Party\") \\\n",
    "                               .mean() \\\n",
    "                               .reset_index()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE:** You should NEVER NEVER solve problems like the one above using loops or list comprehensions. This is slow and also misses the entire point of this part of DS100. \n",
    "\n",
    "Before we continue, we'll print out the election dataset again for your convenience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Question 6a\n",
    "Using `groupby.agg` or one of the shorthand methods (`groupby.min`, `groupby.first`, etc.), create a Series `best_result_percentage_only` that returns a Series showing the entire best result for every party, sorted in decreasing order. Your Series should include only parties which have earned at least 10% of the vote in some election. Your result should look like this:\n",
    "\n",
    "<code>\n",
    "Party\n",
    "Democratic               61.344703\n",
    "Republican               60.907806\n",
    "Democratic-Republican    57.210122\n",
    "National Union           54.951512\n",
    "Whig                     53.051213\n",
    "Liberal Republican       44.071406\n",
    "National Republican      43.796073\n",
    "Northern Democratic      29.522311\n",
    "Progressive              27.457433\n",
    "American                 21.554001\n",
    "Independent              18.956298\n",
    "Southern Democratic      18.138998\n",
    "American Independent     13.571218\n",
    "Constitutional Union     12.639283\n",
    "Free Soil                10.138474\n",
    "Name: %, dtype: float64\n",
    "</code>\n",
    "<br/>\n",
    "\n",
    "A list of named `groupby.agg` shorthand methods is [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#aggregation) (you'll have to scroll down about one page).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:17.183136Z",
     "start_time": "2020-09-16T20:55:17.172696Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "...\n",
    "# put your code above this line\n",
    "best_result_percentage_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 6b  \n",
    "Repeat Question 6a. However, this time, your result should be a DataFrame showing all available information rather than only the percentage as a series.\n",
    "\n",
    "This question is trickier than Question 6a. Make sure to check the Lecture 4 slides if you're stuck! It's very easy to make a subtle mistake that shows Woodrow Wilson and Howard Taft both winning the 2020 election.\n",
    "\n",
    "For example, the first 3 rows of your table should be:\n",
    "\n",
    "|Party | Year | Candidate      | Popular Vote | Result | %         |\n",
    "|------|------|----------------|--------------|--------|-----------|\n",
    "|**Democratic**  | 1964 | Lyndon Johnson | 43127041      | win   | 61.344703 |\n",
    "|**Republican**  | 1972 | Richard Nixon | 47168710      | win   | 60.907806 |\n",
    "|**Democratic-Republican**  | 1824 | Andrew Jackson | 151271      | loss   | 57.210122 |\n",
    "\n",
    "Note that the index is `Party`. In other words, don't use `reset_index`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:18.356549Z",
     "start_time": "2020-09-16T20:55:18.350541Z"
    }
   },
   "outputs": [],
   "source": [
    "...\n",
    "# put your code above this line\n",
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our DataFrame contains a number of parties which have never had a successful presidential run. For example, the 2020 elections included candiates from the Libertarian and Green parties, neither of which have elected a president."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "elections.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we were conducting an analysis trying to focus our attention on parties that had elected a president. \n",
    "\n",
    "The most natural approach is to use `groupby.filter`. This is an incredibly powerful but subtle tool for filtering data.\n",
    "\n",
    "As a reminder of how filter works, see [this slide](https://docs.google.com/presentation/d/1FC-cs5MTGSkDzI_7R_ZENgwoHQ4aVamxFOpJuWT0fo0/edit#slide=id.g5ff184b7f5_0_507). \n",
    "The code below accomplishes the task at hand. It does this by creating a function that returns True if and only if a sub-dataframe (a.k.a. group) contains at least one winner. This function in turn uses the [Pandas function \"any\"](https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:19.814724Z",
     "start_time": "2020-09-16T20:55:19.781171Z"
    }
   },
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "def at_least_one_candidate_in_the_frame_has_won(frame):\n",
    "    \"\"\"Returns df with rows only kept for parties that have\n",
    "    won at least one election\n",
    "    \"\"\"\n",
    "    return (frame[\"Result\"] == 'win').any()\n",
    "\n",
    "winners_only = (\n",
    "    elections\n",
    "        .groupby(\"Party\")\n",
    "        .filter(at_least_one_candidate_in_the_frame_has_won)\n",
    ")\n",
    "winners_only.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately we could have used a `lambda` function instead of explicitly defining a named function using `def`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell (alternative)\n",
    "winners_only = (\n",
    "    elections\n",
    "        .groupby(\"Party\")\n",
    "        .filter(lambda x : (x[\"Result\"] == \"win\").any())\n",
    ")\n",
    "winners_only.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "For your exercise, you'll do a less restrictive filtering of the elections data.\n",
    "\n",
    "**Exercise**: Using `filter`, create a DataFrame `major_party_results_since_1988` that includes all election results starting in 1988, but only show a row if the Party it belongs to has earned at least 1% of the popular vote in ANY election since 1988.\n",
    "\n",
    "For example, in 1988, you should not include the `New Alliance` candidate, since this party has not earned 1% of the vote since 1988. However, you should include the `Libertarian` candidate from 1988 despite only having 0.47 percent of the vote in 1988, because in 2016 and 2020, the Libertarian candidates Gary Johnson and Jo Jorgensen exceeded 1% of the vote.\n",
    "\n",
    "For example, the first three rows of the table you generate should look like:\n",
    "\n",
    "|     |   Year | Candidate         | Party       |   Popular vote | Result   |         % |\n",
    "|----:|-------:|:------------------|:------------|---------------:|:---------|----------:|\n",
    "| 135 |   1988 | George H. W. Bush | Republican  |       48886597 | win      | 53.5188   |\n",
    "| 137 |   1988 | Michael Dukakis   | Democratic  |       41809074 | loss     | 45.7707   |\n",
    "| 138 |   1988 | Ron Paul          | Libertarian |         431750 | loss     |  0.47266  |\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6c\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:21.762599Z",
     "start_time": "2020-09-16T20:55:21.743430Z"
    }
   },
   "outputs": [],
   "source": [
    "...\n",
    "major_party_results_since_1988.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides special purpose functions for working with specific common data types such as strings and dates. For example, the code below provides the length of every Candidate's name from our elections dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections[\"Candidate\"].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Exercise**: Using `.str.split`. Create a new DataFrame called `elections_with_first_name` with a new column `First Name` that is equal to the Candidate's first name.\n",
    "\n",
    "See the Pandas `str` [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html) for documentation on using `str.split`.\n",
    "\n",
    "Hint: Use `[0]` somewhere in your code.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T03:07:32.775469Z",
     "start_time": "2020-09-16T03:07:32.769402Z"
    }
   },
   "outputs": [],
   "source": [
    "elections_with_first_name = elections.copy()\n",
    "# your code here\n",
    "...\n",
    "# end your code\n",
    "elections_with_first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a table with the frequency of all names from 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "baby_names_2020 = (\n",
    "    baby_names.query('Year == 2020')\n",
    "              .groupby(\"Name\")\n",
    "              .sum()[[\"Count\"]]\n",
    "              .reset_index()\n",
    ")\n",
    "baby_names_2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Exercise**: Using the `pd.merge` function described in lecture, combine the `baby_names_2020` table with the `elections_with_first_name` table you created earlier to form `presidential_candidates_and_name_popularity`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidential_candidates_and_name_popularity = ...\n",
    "presidential_candidates_and_name_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun: Which historical presidential candidates have names that were the least and most popular in 2020? Note: Here you'll observe a common problem in data science -- one of the least popular names is actually due to the fact that one recent president was so commonly known by his nickname that he appears named as such in the database from which you pulled election results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your optional code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q7b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Bonus Exercises\n",
    "\n",
    "The following exercises are optional and use the `ca_baby_names` dataset defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "ca_baby_names = baby_names.query('State == \"CA\"')\n",
    "ca_baby_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorted Female Name Counts\n",
    "\n",
    "Create a Series `female_name_since_2000_count` which gives the total number of occurrences of each name for female babies born in California from the year 2000 or later. The index should be the name, and the value should be the total number of births. Your Series should be ordered in decreasing order of count. For example, your first row should have index \"Emily\" and value 52334, because 52334 Emilys have been born since the year 2000 in California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:57:41.891381Z",
     "start_time": "2020-09-16T20:57:41.845507Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q7b_answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "...\n",
    "female_name_since_2000_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counts for All Names\n",
    "\n",
    "Using `groupby`, create a Series `count_for_names_2020` listing all baby names from 2020 in California, in decreasing order of popularity. The result should not be broken down by sex! If a name is used by both male and female babies, the number you provide should be the total.\n",
    "\n",
    "**Note:** *In this question we are now computing the number of registered babies with a given name.* \n",
    "\n",
    "For example, `count_for_names_2020[\"Noah\"]` should be the number 2631 because in 2018 there were 2631 Noahs born (23 female and 2608 male)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:57:42.257127Z",
     "start_time": "2020-09-16T20:57:42.235011Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q7a_answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "...\n",
    "count_for_names_2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Explore the Data Set\n",
    "\n",
    "The popularity of some baby names may be influenced by cultural phenomena, such as a political figure coming to power.  Below, we plot the popularity of name Hillary for female babies in Calfiornia over time. What do you notice about this plot? What real-world events in the U.S. occurred when there was a steep drop in babies named Hillary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "hillary_baby_name = baby_names[(baby_names['Name'] == 'Hillary') & (baby_names['State'] == 'CA') & (baby_names['Sex'] == 'F')]\n",
    "plt.plot(hillary_baby_name['Year'], hillary_baby_name['Count'])\n",
    "plt.title(\"Hillary Popularity Over Time\")\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above is hard coded to generate a dataframe representing the popularity of the female name Hillary in the state of California. While this approach works, it's inelegant.\n",
    "\n",
    "Here we'll use a more elegant approach that builds a dataframe such that:\n",
    "1. It contains ALL names.\n",
    "2. The counts are summed across all 50 states, not just California.\n",
    "\n",
    "To do this, we use `groupby`, though here we're grouping on **two columns** (\"Name\" and \"Year\") instead of just one. After grouping, we use the `sum` aggregation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "counts_aggregated_by_name_and_year = baby_names.groupby([\"Name\", \"Year\"]).sum()\n",
    "counts_aggregated_by_name_and_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the resulting DataFrame is multi-indexed, i.e. it has two indices. The outer index is the Name, and the inner index is the Year. \n",
    "\n",
    "In order to visualize this data, we'll use `reset_index` in order to set the index back to an integer and transform the Name and Year back into columnar data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "counts_aggregated_by_name_and_year = counts_aggregated_by_name_and_year.reset_index()\n",
    "counts_aggregated_by_name_and_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to before, we can plot the popularity of a given name by selecting the name we want to visualize. The code below is very similar to the plotting code above, except that we use query to get the name of interest instead of using a boolean array. \n",
    "\n",
    "**Note**: Here we use a special syntax `@name_of_interest` to tell the query command to use the python variable `name_of_interest`.\n",
    "\n",
    "Try out some other names and see what trends you observe. Note that since this is the American social security database, international names are not well represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "name_of_interest = 'Hillary'\n",
    "chosen_baby_name = counts_aggregated_by_name_and_year.query(\"Name == @name_of_interest\")\n",
    "plt.plot(chosen_baby_name['Year'], chosen_baby_name['Count'])\n",
    "plt.title(f\"Popularity Of {name_of_interest} Over Time\")\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
