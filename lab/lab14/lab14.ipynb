{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab14.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab 14: Decision Trees and Random Forests\n",
    "\n",
    "In this assignment, we will have you train a multi-class classifier with three different models (one-vs-rest logistic regression, decision tree, random forest) and compare the accuracies and decision boundaries created by each. We'll be looking at a dataset of per-game stats for all NBA players in the 2018-19 season. This dataset comes from [basketball-reference.com](https://www.basketball-reference.com/).\n",
    "\n",
    "### Due Date\n",
    "\n",
    "This assignment is due on **Tuesday, December 2nd at 11:59 pm PDT.**\n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about this assignment, we ask that you **write your solutions individually**. If you discuss the assignment with others, please **include their names** in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators:** *list names here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "# ignore the warning you might get from importing ensemble from sklearn\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_data = pd.read_csv(\"nba18-19.csv\")\n",
    "nba_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal will be to predict a player's position given several other features. The 5 positions in basketball are PG, SG, SF, PF, and C (which stand for point guard, shooting guard, small forward, power forward, and center). This information is contained in the `Pos` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_data['Pos'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we could set out to try and perform 5-class classification, the results (and visualizations) are slightly more interesting if we try and categorize players into 1 of 3 categories: **guard**, **forward**, and **center**. The below code will take the `Pos` column of our dataframe and use it to create a new column `Pos3` that consist of values G, F, and C (which stand for guard, forward, and center)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_position(pos):\n",
    "    if 'F' in pos:\n",
    "        return 'F'\n",
    "    elif 'G' in pos:\n",
    "        return 'G'\n",
    "    return 'C'\n",
    "\n",
    "nba_data['Pos3'] = nba_data['Pos'].apply(basic_position)\n",
    "nba_data['Pos3'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, since there are **many** players in the NBA (in the 2018-19 season there were 530 unique players), our visualizations can get noisy and messy. Let's restrict our data to only contain rows for players that averaged 10 or more points per game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_data = nba_data[nba_data['PTS'] > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at a scatterplot of Rebounds (`TRB`) vs. Assists (`AST`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = nba_data, x = 'AST', y = 'TRB', hue = 'Pos3');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, when using just rebounds and assists as our features, we see pretty decent cluster separation. That is, Centers, Forwards, and Guards appear in different regions of the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 1: Evaluating Split Quality\n",
    "\n",
    "We will explore different ways to evaluate split quality for classification and regression trees in this question.\n",
    "\n",
    "### Question 1a\n",
    "\n",
    "In lecture we defined the entropy S of a node as:\n",
    "\n",
    "$$ S = -\\sum_{C} p_C \\log_{2} p_C $$\n",
    "\n",
    "where $p_C$ is the proportion of data points in a node with label $C$. This function helped us determine the unpredictability of a node in a decision tree. \n",
    "\n",
    "Implement the `entropy` function, which outputs the entropy of a node with a given set of labels. The `labels` parameter is a list of labels in our dataset. For example, `labels` could be `['G', 'G', 'F', 'F', 'C', 'C']`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels):\n",
    "    ...\n",
    "\n",
    "entropy(nba_data['Pos3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1b\n",
    "\n",
    "The decision tree visualizations in lecture contained nodes with a `gini` parameter. This depicts the node's Gini impurity, which is the chance that a sample would be misclassified if randomly assigned at this point. Gini impurity is a popular alternative to entropy for determining the best split at a node, and it is in fact the default criterion for scikit-learn's `DecisionTreeClassifier`. We can calculate the Gini impurity of a node with the formula ($p_C$ is the proportion of data points in a node with label $C$):\n",
    "\n",
    "$$ G = 1 - \\sum_{C} {p_C}^2 $$\n",
    "\n",
    "Note that no logarithms are involved in the calculation of Gini impurity, which can make it faster to compute compared to entropy.\n",
    "\n",
    "Implement the `gini_impurity` function, which outputs the Gini impurity of a node with a given set of labels. The `labels` parameter is defined similarly to the previous part.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(labels):\n",
    "    ...\n",
    "\n",
    "gini_impurity(nba_data['Pos3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an optional exercise in probability, try to think of a way to derive the formula for Gini impurity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It usually does not make sense to use entropy and Gini impurity for regression trees because the response variable is continuous. However, we can use the variance of the response values in a node as an alternative to entropy and Gini impurity. Recall that the variance is defined as:\n",
    "\n",
    "$$ \\sigma^2 = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\mu)^2 $$\n",
    "\n",
    "where $\\mu$ is the mean, $N$ is the total number of data points, and $x_i$ is the value of each data point.\n",
    "\n",
    "Here we define variance as we have previously done in the course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(values):\n",
    "    return np.mean((values - np.mean(values)) ** 2)\n",
    "    \n",
    "variance(nba_data['PTS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1c\n",
    "\n",
    "In lecture, we used weighted entropy as a loss function to help us determine the best split. Recall that the weighted entropy is given by:\n",
    "\n",
    "$$ L = \\frac{N_1 S(X) + N_2 S(Y)}{N_1 + N_2} $$\n",
    "\n",
    "$N_1$ is the number of samples in the left node $X$, and $N_2$ is the number of samples in the right node $Y$. This notion of a weighted average can be extended to other metrics such as Gini impurity and variance simply by changing the $S$ (entropy) function to $G$ (Gini impurity) or $\\sigma^2$ (variance).\n",
    "\n",
    "First, implement the `weighted_metric` function. The `left` parameter is a list of labels or values in the left node $X$, and the `right` parameter is a list of labels or values in the right node $Y$. The `metric` parameter is a function which can be `entropy`, `gini_impurity`, or `variance`. For `entropy` and `gini_impurity`, you may assume that `left` and `right` contain discrete labels. For `variance`, you may assume that `left` and `right` contain continuous values.\n",
    "\n",
    "Then, assign `we_pos3_age_30` to the weighted entropy (in the `Pos3` column) of a split that partitions `nba_data` into two groups: a group with players who are 30 years old or older and a group with players who are younger than 30 years old.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_metric(left, right, metric):\n",
    "    ...\n",
    "\n",
    "we_pos3_age_30 = ...\n",
    "we_pos3_age_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not go over the entire decision tree fitting process in this assignment, but you now have the basic tools to fit a decision tree. As an optional exercise, try to think about how you would extend these tools to fit a decision tree from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Classification\n",
    "\n",
    "Let's switch gears to classification with the NBA dataset.\n",
    "\n",
    "## One-vs-Rest Logistic Regression\n",
    "\n",
    "We only discussed binary logistic regression in class, but there is a natural extension to binary logistic regression called one-vs-rest logistic regression for multiclass classification. In essence, one-vs-rest logistic regression simply builds one binary logistic regression classifier for each of the $N$ classes (in this scenario $N = 3$). We then predict the class corresponding to the classifier that gives the highest probability among the $N$ classes.\n",
    "\n",
    "Before using logistic regression, let's first split `nba_data` into a training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_train, nba_test = train_test_split(nba_data, test_size=0.25, random_state=100)\n",
    "nba_train = nba_train.sort_values(by='Pos')\n",
    "nba_test = nba_test.sort_values(by='Pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2a\n",
    "\n",
    "In the cell below, set `logistic_regression_model` to be a one-vs-rest logistic regression model. Then, fit that model using the `AST` and `TRB` columns (in that order) from `nba_train` as our features, and `Pos3` as our response variable.\n",
    "\n",
    "Remember, [`sklearn.linear_model.LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) has already been imported for you. There is an optional parameter **`multi_class`** you need to specify in order to make your model a multi-class one-vs-rest classifier. See the documentation for more details.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see our classifier in action, we can use `logistic_regression_model.predict` and see what it outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_train['Predicted (OVRLR) Pos3'] = logistic_regression_model.predict(nba_train[['AST', 'TRB']])\n",
    "nba_train[['AST', 'TRB', 'Pos3', 'Predicted (OVRLR) Pos3']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model does decently well here, as you can see visually above. Below, we compute the training accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_training_accuracy = logistic_regression_model.score(nba_train[['AST', 'TRB']], nba_train['Pos3'])\n",
    "lr_training_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the test accuracy as well by looking at `nba_test` instead of `nba_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_test_accuracy = logistic_regression_model.score(nba_test[['AST', 'TRB']], nba_test['Pos3'])\n",
    "lr_test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's draw the decision boundary for this logistic regression classifier, and see how the classifier performs on both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns_cmap = ListedColormap(np.array(sns.color_palette())[0:3, :])\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(0, 12, 0.02), np.arange(0, 16, 0.02))\n",
    "Z_string = logistic_regression_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "categories, Z_int = np.unique(Z_string, return_inverse = True)\n",
    "Z_int = Z_int.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z_int, cmap = sns_cmap)\n",
    "sns.scatterplot(data = nba_train, x = 'AST', y = 'TRB', hue = 'Pos3')\n",
    "plt.title('Logistic Regression on nba_train');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_cmap = ListedColormap(np.array(sns.color_palette())[0:3, :])\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(0, 12, 0.02), np.arange(0, 16, 0.02))\n",
    "Z_string = logistic_regression_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "categories, Z_int = np.unique(Z_string, return_inverse = True)\n",
    "Z_int = Z_int.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z_int, cmap = sns_cmap)\n",
    "sns.scatterplot(data = nba_test, x = 'AST', y = 'TRB', hue = 'Pos3')\n",
    "plt.title('Logistic Regression on nba_test');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our one-vs-rest logistic regression was able to find a linear decision boundary between the three classes. It generally classifies centers as players with a lot of rebounds, forwards as players with a medium number of rebounds and a low number of assists, and guards as players with a low number of rebounds. \n",
    "\n",
    "Note: In practice we would use many more features â€“ we only used 2 here just so that we could visualize the decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Decision Trees\n",
    "\n",
    "### Question 2b\n",
    "\n",
    "Let's now create a decision tree classifier on the same training data `nba_train`, and look at the resulting decision boundary. \n",
    "\n",
    "In the following cell, first, use [`tree.DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) to fit a model using the same features and response as above, and call this model `decision_tree_model`. Set the `random_state` parameter to 42. Set the criterion to be `gini`.\n",
    "\n",
    "**Hint:** Your code will be mostly the same as the previous part.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decision_tree_model = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's draw the decision boundary for this decision tree classifier, and see how the classifier performs on both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(np.arange(0, 12, 0.02), np.arange(0, 16, 0.02))\n",
    "Z_string = decision_tree_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "categories, Z_int = np.unique(Z_string, return_inverse = True)\n",
    "Z_int = Z_int.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z_int, cmap = sns_cmap)\n",
    "sns.scatterplot(data = nba_train, x = 'AST', y = 'TRB', hue = 'Pos3')\n",
    "plt.title('Decision Tree on nba_train');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(np.arange(0, 12, 0.02), np.arange(0, 16, 0.02))\n",
    "Z_string = decision_tree_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "categories, Z_int = np.unique(Z_string, return_inverse = True)\n",
    "Z_int = Z_int.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z_int, cmap = sns_cmap)\n",
    "sns.scatterplot(data = nba_test, x = 'AST', y = 'TRB', hue = 'Pos3')\n",
    "plt.title('Decision Tree on nba_test');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the training and test accuracies of the decision tree model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_training_accuracy = decision_tree_model.score(nba_train[['AST', 'TRB']], nba_train['Pos3'])\n",
    "dt_test_accuracy = decision_tree_model.score(nba_test[['AST', 'TRB']], nba_test['Pos3'])\n",
    "dt_training_accuracy, dt_test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Random Forests\n",
    "\n",
    "### Question 2c\n",
    "\n",
    "Let's now create a random forest classifier on the same training data `nba_train` and look at the resulting decision boundary. \n",
    "\n",
    "In the following cell, use [`ensemble.RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to fit a model using the same features and response as above, and call this model `random_forest_model`. Use 20 trees in your random forest classifier, and set the `random_state` parameter to 42.\n",
    "\n",
    "**Hint:** Your code for both parts will be mostly the same as the first few parts of this question.\n",
    "\n",
    "**Hint:** Look at the `n_estimators` parameter of `ensemble.RandomForestClassifier`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2c\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's draw the decision boundary for this random forest classifier, and see how the classifier performs on both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(np.arange(0, 12, 0.02), np.arange(0, 16, 0.02))\n",
    "Z_string = random_forest_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "categories, Z_int = np.unique(Z_string, return_inverse = True)\n",
    "Z_int = Z_int.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z_int, cmap = sns_cmap)\n",
    "sns.scatterplot(data = nba_train, x = 'AST', y = 'TRB', hue = 'Pos3')\n",
    "plt.title('Random Forest on nba_train');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(np.arange(0, 12, 0.02), np.arange(0, 16, 0.02))\n",
    "Z_string = random_forest_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "categories, Z_int = np.unique(Z_string, return_inverse = True)\n",
    "Z_int = Z_int.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z_int, cmap = sns_cmap)\n",
    "sns.scatterplot(data = nba_test, x = 'AST', y = 'TRB', hue = 'Pos3')\n",
    "plt.title('Random Forest on nba_test');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the training and test accuracies of the random forest model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_accuracy = random_forest_model.score(nba_train[['AST', 'TRB']], nba_train['Pos3'])\n",
    "rf_test_accuracy = random_forest_model.score(nba_test[['AST', 'TRB']], nba_test['Pos3'])\n",
    "rf_train_accuracy, rf_test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2d\n",
    "\n",
    "Below is a summary of the training and test accuracies for the three models you created (multiclass one-vs-rest logistic regression, decision tree, random forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = [lr_training_accuracy, lr_test_accuracy, dt_training_accuracy, dt_test_accuracy, rf_train_accuracy, rf_test_accuracy]\n",
    "index = ['OVR Logistic Regression', 'Decision Tree', 'Random Forest']\n",
    "df = pd.DataFrame([(lr_training_accuracy, lr_test_accuracy), \n",
    "                   (dt_training_accuracy, dt_test_accuracy),\n",
    "                   (rf_train_accuracy, rf_test_accuracy)], \n",
    "                  columns=['Training Accuracy', 'Test Accuracy'], index=index)\n",
    "df.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "Looking at the three models, which model performed the best on the training set, and which model performed the best on the test set? How are the training and test accuracy related for the three models, and how do the decision boundaries generated for each of the three models relate to the model's performance?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2d\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (ungraded)\n",
    "\n",
    "In Homework 7, we used linear regression to predict housing prices in Cook county, Chicago; however, what would happen if we tried to use a different prediction method? Try fitting a decision tree instead of fitting a linear regression model for your final model in Homework 7. What do you notice about the training error and the test error for the decision tree regressor? Is one significantly larger than the other? If so, what methods could we use to make this error lower?\n",
    "\n",
    "Now, try fitting a random forest regressor instead of a single decision tree. What do you notice about the training error and the test error for the random forest, and how does this compare to the training and test error of a single decision tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
