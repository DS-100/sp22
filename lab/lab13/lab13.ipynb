{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab13.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab 13: Logistic Regression\n",
    "\n",
    "In this lab you will build a logistic regression model and evaluate the performance of your model.\n",
    "\n",
    "### Due Date\n",
    "\n",
    "This assignment is due on **Tuesday, November 23, at 11:59PM PDT**.\n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about\n",
    "the homework, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others please **include their names** at the top\n",
    "of your solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators:** *list names here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import cufflinks as cf\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "py.init_notebook_mode(connected=False)\n",
    "cf.set_config_file(offline=False, world_readable=True, theme='ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "dataset",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "In this lab we will be working with the breast cancer dataset. This dataset can be loaded using the `sklearn.datasets.load_breast_cancer()` method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "loaddata",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data = sklearn.datasets.load_breast_cancer()\n",
    "# data is actually a dictionnary\n",
    "print(data.keys())\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data format is not a `pandas.DataFrame` so we will need to do some preprocessing to create a new DataFrame from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "dataframe",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "fitone",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Let us try to fit a simple model with only one feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "buildxy",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Define our features/target\n",
    "X = df[[\"mean radius\"]]\n",
    "# Target data['target'] = 0 is malignant, 1 is benign\n",
    "Y = (data.target == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "split",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a 75-25 train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test,y_train,y_test = train_test_split(X,Y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Training Data Size: {len(x_train)}\")\n",
    "print(f\"Test Data Size: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q1_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1\n",
    "\n",
    "Let's first fit a logistic regression model using the training set. \n",
    "\n",
    "For this problem, we will use the existing `LogisticRegression` implementation in sklearn.\n",
    "\n",
    "Fill in the code below to compute the training and testing accuracy, defined as:\n",
    "\n",
    "$$\n",
    "\\text{Training Accuracy} = \\frac{1}{n_{train\\_set}} \\sum_{i \\in {train\\_set}} {\\mathbb{1}_{y_i == \\hat{y_i}}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Testing Accuracy} = \\frac{1}{n_{test\\_set}} \\sum_{i \\in {test\\_set}} {\\mathbb{1}_{y_i == \\hat{y_i}}}\n",
    "$$\n",
    "\n",
    "where $\\hat{y_i}$ is the prediction of our model, $y_i$ the true value, and $\\mathbb{1}_{y_i == \\hat{y_i}}$ an indicator function where $\\mathbb{1}_{y_i == \\hat{y_i}} = 1$ if ${y_i} = \\hat{y_i}$, and $\\mathbb{1}_{y_i == \\hat{y_i}} = 0$ if ${y_i} \\neq \\hat{y_i}$\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "lr = sklearn.linear_model.LogisticRegression(fit_intercept=True, solver = 'lbfgs')\n",
    "\n",
    "lr.fit(x_train,y_train) \n",
    "train_accuracy = ...\n",
    "test_accuracy = ...\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2\n",
    "It seems we can get a very high test accuracy. How about precision and recall?  \n",
    "- Precision (also called positive predictive value) is the fraction of true positives among the total number of data points predicted as positive.  \n",
    "- Recall (also known as sensitivity) is the fraction of true positives among the total number of data points with positive labels.\n",
    "\n",
    "Precision measures the ability of our classifier to not predict negative samples as positive, while recall is the ability of the classifier to find all the positive samples.\n",
    "\n",
    "To understand the link between precision and recall, it's useful to create a confusion matrix of our predictions. Luckily, `sklearn.metrics` provides us with such a function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_display",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, lr.predict(x_test))\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "class_names = ['False', 'True']\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plt.grid(False)\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plt.grid(False)\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_text2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Mathematically, Precision and Recall are defined as:\n",
    "$$\n",
    "\\text{Precision} = \\frac{n_{true\\_positives}}{n_{true\\_positives} + n_{false\\_positives}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{n_{true\\_positives}}{n_{true\\_positives} + n_{false\\_negatives}}\n",
    "$$\n",
    "\n",
    "Below is a graphical illustration of precision and recall:\n",
    "![precision_recall](precision_recall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-sd",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now let's compute the precision and recall for the test set using the model we got from Question 1.  \n",
    "\n",
    "**Do not** use `sklearn.metrics` for this computation.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_test) \n",
    "\n",
    "precision = ...\n",
    "recall = ...\n",
    "\n",
    "print(f'precision = {precision:.4f}')\n",
    "print(f'recall = {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_question",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Our precision is fairly high while our recall is a bit lower. Why might we observe these results? Please consider the following plots, which display the distribution of the target variable in the training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_display2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "sns.countplot(x=y_train, ax=axes[0]);\n",
    "sns.countplot(x=y_test, ax=axes[1]);\n",
    "\n",
    "axes[0].set_title('Train')\n",
    "axes[1].set_title('Test')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "###  Question 3\n",
    "Now let's try to analyze the cross entropy loss from logistic regression. The average loss across our entire dataset is:\n",
    "\n",
    "$$R(\\theta) = -\\frac{1}{n} \\sum_{i=1}^n \\left( y_i \\log(\\hat{y_i}) + (1 - y_i) \\log(1 - \\hat{y_i})  \\right) $$\n",
    "\n",
    "where $\\hat{y_i} = \\sigma(X_i^T \\theta)$. Here, $X_i$ is the i'th row of our design matrix $X$, $\\theta$ is our weight vector $[\\theta_1, \\theta_2]^T$ where $\\theta_1$ corresponds to the weight for the mean radius feature and $\\theta_2$ corresponds to the bias term, and $\\sigma$ is the sigmoid activation function defined below:\n",
    "\n",
    "$\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n",
    "\n",
    "**Note**: In this class, when performing linear algebra operations we interpret both rows and columns as column vectors. So if we wish to calculate the dot product between row $X_i$ and a vector $v$, we would write $X_i^Tv$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.array([lr.coef_[0][0],\n",
    "                  lr.intercept_[0]])\n",
    "X_new = np.hstack([X,\n",
    "                 np.ones([len(X), 1])]) # This is adding a coefficient of 1 for the intercept term\n",
    "print(theta, '\\n')\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "\n",
    "def lr_loss(theta, X, Y):\n",
    "    '''\n",
    "    Compute the cross entropy loss using X, Y, and theta. You should not need to use a for loop. \n",
    "    Hint: The notation B @ v means: compute the matrix multiplication Bv.\n",
    "\n",
    "    Args:\n",
    "        theta: The model parameters. \n",
    "        X: The design matrix\n",
    "        Y: The label \n",
    "\n",
    "    Return:\n",
    "        The cross entropy loss.\n",
    "    '''\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a plot showing the cross-entropy loss for various values of $\\theta_1$ and $\\theta_2$ (note that they are represented as x and y in the graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_display",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "with np.errstate(invalid='ignore', divide='ignore'):\n",
    "    uvalues = np.linspace(-8,8,70)\n",
    "    vvalues = np.linspace(-5,5,70)\n",
    "    (u,v) = np.meshgrid(uvalues, vvalues)\n",
    "    thetas = np.vstack((u.flatten(),v.flatten()))\n",
    "    lr_loss_values = np.array([lr_loss(t, X_new, Y) for t in thetas.T])\n",
    "    lr_loss_surface = go.Surface(name=\"Logistic Regression Loss\",\n",
    "            x=u, y=v, z=np.reshape(lr_loss_values,(len(uvalues), len(vvalues))),\n",
    "            contours=dict(z=dict(show=True, color=\"gray\", project=dict(z=True)))\n",
    "        )\n",
    "    fig = go.Figure(data=[lr_loss_surface])\n",
    "    fig.update_layout(\n",
    "        scene = dict(\n",
    "            xaxis_title='theta_1',\n",
    "            yaxis_title='theta_2',\n",
    "            zaxis_title='Loss'),\n",
    "            width=700,\n",
    "            margin=dict(r=20, l=10, b=10, t=10))\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Describe one interesting observation about the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
