{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 22 â€“ Data 100, Fall 2021\n",
    "\n",
    "by Suraj Rampure\n",
    "\n",
    "adapted from Josh Hug, Joseph Gonzalez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from scipy.optimize import minimize\n",
    "import sklearn.linear_model as lm\n",
    "\n",
    "# plt.rcParams['figure.figsize'] = (4, 4)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['lines.linewidth'] = 3\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivating Logistic Regression\n",
    "\n",
    "In this lecture, we will look at data from the 2017-18 NBA season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are eventually going to want to perform **binary classification**, which is where we predict a 1 or 0. A reasonable thing to want to do given this data is to predict whether or not a team wins. Right now, the `WL` column consists of `\"W\"` and `\"L\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix that, so that wins are encoded as `1` and losses are encoded as `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"WON\"] = df[\"WL\"]\n",
    "df[\"WON\"] = df[\"WON\"].replace(\"W\", 1)\n",
    "df[\"WON\"] = df[\"WON\"].replace(\"L\", 0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a row for each team and each game in this dataset. It contains the `FG_PCT` (field goal percentage) for each team per game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FG_PCT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and get the field goal percentage difference between two teams in a single game. We will then try and use this value to predict whether or not a team wins, given their field goal percentage difference.\n",
    "\n",
    "This data cleaning and EDA is not the point of this lecture, but you may want to come back to this and try and understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_team = df.groupby(\"GAME_ID\").first()\n",
    "opponent = df.groupby(\"GAME_ID\").last()\n",
    "games = one_team.merge(opponent, left_index = True, right_index = True, suffixes = [\"\", \"_OPP\"])\n",
    "games[\"FG_PCT_DIFF\"] = games[\"FG_PCT\"] - games[\"FG_PCT_OPP\"]\n",
    "games['WON'] = games['WL'].replace('L', 0).replace('W', 1)\n",
    "games = games[['TEAM_NAME', 'MATCHUP', 'WON', 'FG_PCT_DIFF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by looking at a `sns.jointplot` of `FG_PCT_DIFF` and `WON`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data = games, x = \"FG_PCT_DIFF\", y = \"WON\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reasonable thing to do here might be to model the **probability of winning, given `FG_PCT_DIFF`**.\n",
    "\n",
    "We already know how to use ordinary least squares, right? Why not use it here?\n",
    "\n",
    "We'll also jitter the data, to get a better picture of what it looks like. But the line of best fit that's being drawn is on top of the original, non-jittered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data = games, x = \"FG_PCT_DIFF\", y = \"WON\", \n",
    "              y_jitter = 0.1, \n",
    "              kind=\"reg\", \n",
    "              ci=False,\n",
    "              joint_kws={'line_kws':{'color':'green'}});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The green line drawn is a valid model. It is the line that minimizes MSE for this set of $x$ (`FG_PCT_DIFF`) and $y$ (`WON`) data.\n",
    "\n",
    "But there are some issues:\n",
    "- The outputs are bigger than 0 and less than 1. How do we interpret that?\n",
    "- This is very susceptible to outliers. See:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games2 = games.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games2.iloc[0] = ['hello', 'hello', 1, 120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.jointplot(data = games2, x = \"FG_PCT_DIFF\", y = \"WON\", \n",
    "              y_jitter = 0.1, \n",
    "              kind=\"reg\", \n",
    "              ci=False,\n",
    "              joint_kws={'line_kws':{'color':'green'}});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a better model. Let's try and replicate the **graph of averages** from Lecture 12, on Simple Linear Regression. Recall, we\n",
    "- binned the $x$ axis.\n",
    "- took the average $y$ value for each bin on the $x$ axis.\n",
    "\n",
    "We will do the same thing here, albeit with slightly different code. Here, we will formally partition the $x$-axis into 20 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = pd.cut(games[\"FG_PCT_DIFF\"], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games[\"bin\"] = [(b.left + b.right) / 2 for b in bins]\n",
    "games[\"bin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know which `\"bin\"` each game belongs to. We can plot the average `WON` for each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_rates_by_bin = games.groupby(\"bin\")[\"WON\"].mean()\n",
    "win_rates_by_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(win_rates_by_bin, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data = games, x = \"FG_PCT_DIFF\", y = \"WON\", \n",
    "              y_jitter = 0.1, \n",
    "              kind=\"reg\", \n",
    "              ci=False,\n",
    "              joint_kws={'line_kws':{'color':'green'}});\n",
    "plt.plot(win_rates_by_bin, 'r', linewidth = 5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like our red graph of averages does a much better job at matching the data than our simple linear regression line.\n",
    "\n",
    "**What is this graph of averages plotting?** Since the $y$ axis is only 0s and 1s, and we took the mean of the $y$-values in each bin for a given $x$, the graph of average is plotting the **proportion** of times a team won, given their `FG_PCT_DIFF`. Remember, `WON = 1` each time a team won.\n",
    "\n",
    "**Logistic regression aims to model the probability of an observation belonging to class 1, given some set of features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(t):\n",
    "    return 1 / (1 + np.exp(-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(win_rates_by_bin, 'r', linewidth = 5);\n",
    "x = win_rates_by_bin.index\n",
    "plt.plot(x, sigma(x * 30), 'black', linewidth = 5);\n",
    "plt.xlabel('FG_PCT_DIFF')\n",
    "plt.ylabel('WON');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is this mystery `sigma` function, and why does `sigma(x * 30)` match our graph of averages so well? Well... we're getting there.\n",
    "\n",
    "For now, consider these questions:\n",
    "\n",
    "What are:\n",
    "1. $P(Y = 1 | X = 0.0283)$? \n",
    "2. $P(Y = 0 | X = 0.0283)$? \n",
    "3. $\\frac{P(Y = 1 | X = 0.0283)}{P(Y = 0 | X = 0.0283)}$? In other words, how many wins are there for each loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_rates_by_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **odds** of an event are defined as the probability that it happens divided by the probability that it doesn't happen.\n",
    "\n",
    "If some event happens with probability $p$, then $\\text{odds}(p) = \\frac{p}{1-p}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_by_bin = win_rates_by_bin / (1 - win_rates_by_bin)\n",
    "odds_by_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot the odds of these probabilities, they look exponential:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(odds_by_bin);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we take the log of these odds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.log(odds_by_bin));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that the **log-odds grows linearly with $x$**. \n",
    "\n",
    "In the lecture slides, we formalize what this means, and how this allows us to arrive at the `sigma` function above.\n",
    "\n",
    "## The Logistic Function\n",
    "\n",
    "In the slides, we show that our model is\n",
    "\n",
    "$$P(Y = 1 | x) = \\sigma(x^T \\theta)$$\n",
    "\n",
    "where $$\\sigma(t) = \\frac{1}{1 + e^{-t}}$$\n",
    "\n",
    "Let's explore the shape of the logistic function, $\\sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the vanilla curve $\\sigma(x)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5,5,50)\n",
    "plt.plot(x, sigma(x));\n",
    "plt.xlabel('x')\n",
    "plt.ylabel(r'$\\frac{1}{1 + e^{-x}}$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we look at $\\sigma(\\theta_1 x)$, for several values of $\\theta_1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(li): \n",
    "    return [item for sub in li for item in sub]\n",
    "\n",
    "bs = [-2, -1, -0.5, 2, 1, 0.5]\n",
    "xs = np.linspace(-10, 10, 100)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(10, 6))\n",
    "for ax, b in zip(flatten(axes), bs):\n",
    "    ys = sigma(xs * b)\n",
    "    ax.plot(xs, ys)\n",
    "    ax.set_title(r'$ \\theta_1 = $' + str(b))\n",
    "\n",
    "# add a big axes, hide frame\n",
    "fig.add_subplot(111, frameon=False)\n",
    "# hide tick and tick label of the big axes\n",
    "plt.tick_params(labelcolor='none', top=False, bottom=False,\n",
    "                left=False, right=False)\n",
    "plt.grid(False)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel(r'$ \\frac{1}{1+\\exp(-\\theta_1 \\cdot x)} $')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sigmoids.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the shape of $\\sigma(\\theta_0 + \\theta_1x)$, for different values of $\\theta_0, \\theta_1$. There's quite a bit going on here, so let's use `plotly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for theta1 in [-1,1, 5]:\n",
    "    for theta0 in [-2, 0, 2]:\n",
    "        fig.add_trace(go.Scatter(name=f\"{theta0} + {theta1} x\", x=xs, y=sigma(theta0 + theta1*xs)))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Squared Loss\n",
    "\n",
    "We've chosen a model. It's now time to choose a loss function. Why not squared loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss_single_arg_nba(theta):\n",
    "    x = games[\"FG_PCT_DIFF\"]\n",
    "    y_obs = games[\"WON\"]\n",
    "    y_hat = sigma(x * theta)\n",
    "    return np.mean((y_hat - y_obs) ** 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.linspace(-50, 50, 100)\n",
    "plt.plot(thetas, [mse_loss_single_arg_nba(theta) for theta in thetas])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel(r'$\\theta$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(mse_loss_single_arg_nba, x0 = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(win_rates_by_bin, 'r', linewidth = 5);\n",
    "x = win_rates_by_bin.index\n",
    "plt.plot(x, sigma(x * 29.13), 'black', linewidth = 5);\n",
    "plt.xlabel('FG_PCT_DIFF')\n",
    "plt.ylabel('WON');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So squared loss worked just fine here. But that won't always be the case! Consider this manufacturered example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_x = np.array([[-0.04185564],\n",
    "       [ 0.12799961],\n",
    "       [-0.09528101],\n",
    "       [-0.0058139 ],\n",
    "       [ 0.0870956 ]])\n",
    "\n",
    "rand_y = np.array([[0],\n",
    "       [0],\n",
    "       [1],\n",
    "       [0],\n",
    "       [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rand_x, rand_y, 'b*')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss_single_arg_toy(theta):\n",
    "    x = rand_x\n",
    "    y_obs = rand_y\n",
    "    y_hat = sigma(x * theta)\n",
    "    return np.mean((y_obs - y_hat)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss_single_arg_toy(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the loss surface for this toy data using squared loss with the model $\\hat{y} = \\sigma(\\theta x)$, where $\\theta$ and $x$ are both scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.linspace(-1000, 1000, 100)\n",
    "plt.plot(thetas, [mse_loss_single_arg_toy(theta) for theta in thetas])\n",
    "plt.ylabel(r'MSE($\\theta$)')\n",
    "plt.xlabel(r'$\\theta$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loss surface is not convex! Depending on where we start our optimization search, we'll end up with different results. Let's explore with `scipy.optimize.minimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_theta = minimize(mse_loss_single_arg_toy, x0 = 0)[\"x\"][0]\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rand_x, rand_y, 'b*')\n",
    "xs = np.linspace(-1, 1, 100)\n",
    "plt.plot(xs, sigma(xs * best_theta), color='orange')\n",
    "plt.xlabel('x')\n",
    "plt.legend(['$y$', '$\\hat{y}$']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_theta_2 = minimize(mse_loss_single_arg_toy, x0 = 500)[\"x\"][0]\n",
    "best_theta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rand_x, rand_y, 'b*')\n",
    "xs = np.linspace(min(rand_x), max(rand_x), 100)\n",
    "plt.plot(xs, sigma(xs * best_theta_2), color='orange')\n",
    "plt.xlabel('x')\n",
    "plt.legend(['$y$', '$\\hat{y}$']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only is it not convex, leading to the weird issues above, but squared loss just isn't well-suited for a probability task. Since $\\hat{y_i}$ is between 0 and 1, and $y_i$ is either 0 or 1, the squared loss for a single point $(y_i - \\hat{y_i})^2$ is bounded between 0 and 1.\n",
    "\n",
    "What this means in practice: even if our prediction is terrible, the squared loss is never that large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.arange(0.001, 0.999, 0.01)\n",
    "loss = (1 - y_hat)**2\n",
    "plt.plot(y_hat, loss, color='k')\n",
    "plt.xlabel('$\\hat{y}$: Predicted Chance of Correct Class')\n",
    "plt.ylabel('$(1 - \\hat{y})^2$')\n",
    "plt.title('Squared Loss for One Individual');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivating Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a new loss, called the log loss, for when our true observation is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.arange(0.001, 0.999, 0.01)\n",
    "loss = -np.log(y_hat)\n",
    "plt.plot(y_hat, loss, color='k')\n",
    "plt.xlabel('$\\hat{y}$: Predicted Chance of Correct Class')\n",
    "plt.ylabel('$-\\log(\\hat{y})$')\n",
    "plt.title('Log Loss for one observation when $y = 1$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this penalizes wrong predictions far more than squared loss does.\n",
    "\n",
    "How to read this plot: Suppose the observation we're trying to predict is actually in class 1. If our model gives an 80% chance of being in class 1, the loss is relatively small (around 0.25). \n",
    "\n",
    "If we give only a 40% of being in class 1, the loss is larger (around 1).\n",
    "\n",
    "If we give only a 5% chance of being in class 1, the loss is 3.\n",
    "\n",
    "And if we give a 0% chance of being in class 1, the loss is infinite.\n",
    "\n",
    "What about when the true observation is 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.arange(0.001, 0.999, 0.01)\n",
    "loss = -np.log(1 - y_hat)\n",
    "plt.plot(y_hat, loss, color='k')\n",
    "plt.xlabel('$\\hat{y}$: Predicted Chance of Correct Class')\n",
    "plt.ylabel('$-\\log(1 - \\hat{y})$')\n",
    "plt.title('Log Loss for one observation when $y = 0$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of the formal derivation is in the slides. But the equation for cross-entropy loss for a single observation is\n",
    "\n",
    "$$\\textrm{loss} = -y \\log(\\hat{y}) - (1-y)\\log(1-\\hat{y})$$\n",
    "\n",
    "For us, since $\\hat{y} = \\sigma(x^T \\theta)$, the expression for average cross-entropy loss is\n",
    "\n",
    "$$R(\\theta) = -\\frac{1}{n} \\sum_{i = 1}^n \\big(y_i \\log (\\sigma(\\mathbb{X}_i^T \\theta)) + (1 - y_i) \\log (1 - \\sigma(\\mathbb{X}_i^T \\theta))\\big)$$\n",
    "\n",
    "Let's look at the loss surface for average cross-entropy loss, on our toy data from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y, yhat):\n",
    "    return - y * np.log(yhat) - (1 - y) * np.log(1 - yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mce_loss_single_arg_toy(theta):\n",
    "    x = rand_x\n",
    "    y_obs = rand_y\n",
    "    y_hat = sigma(x * theta)\n",
    "    return np.mean(cross_entropy(y_obs, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.linspace(-1000, 1000, 100)\n",
    "plt.plot(thetas, [mce_loss_single_arg_toy(theta) for theta in thetas], color = 'green')\n",
    "plt.ylabel(r'Mean Cross-Entropy($\\theta$)')\n",
    "plt.xlabel(r'$\\theta$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_theta_mce = minimize(mce_loss_single_arg_toy, x0 = 0)[\"x\"][0]\n",
    "best_theta_mce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the resulting optimal $\\hat{\\theta}$ is slightly different than the one that minimized MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lastly, we can determine the $\\hat{\\theta}$ that minimizes mean cross-entropy loss for our NBA dataset from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mce_loss_single_arg_nba(theta):\n",
    "    x = games[\"FG_PCT_DIFF\"]\n",
    "    y_obs = games[\"WON\"]\n",
    "    y_hat = sigma(theta * x)\n",
    "    return np.mean(cross_entropy(y_obs, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_theta_mce_nba = minimize(mce_loss_single_arg_nba, x0 = 0)[\"x\"][0]\n",
    "best_theta_mce_nba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this is different than the $\\hat{\\theta}$ that minimizes mean squared error for the NBA dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(mse_loss_single_arg_nba, x0 = 0)[\"x\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can manually call `scipy.optimize.minimize` to determine the model parameters that minimize average cross-entropy loss, as we did above. We can then predict probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_theta_mce_nba = minimize(mce_loss_single_arg_nba, x0 = 0)[\"x\"][0]\n",
    "best_theta_mce_nba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probabilities(X, theta):\n",
    "    return sigma(X * theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_probabilities(games['FG_PCT_DIFF'], best_theta_mce_nba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, `scikit-learn` can do this for us.\n",
    "\n",
    "The `lm.LogisticRegression` model is what we want to use here. In order to recreate our specific model, there are a few parameters we need to set:\n",
    "- `penalty = 'none'`: by default, `lm.LogisticRegression` uses regularization. This is generally a good idea, but we haven't yet covered regularization with logistic regression (next time!).\n",
    "- `fit_intercept = False`: our toy model does not currently have an intercept term.\n",
    "- `solver = 'lbgfs'`: need to specify a numerical optimization routine for the model (similar to gradient descent). `lbfgs` is one such type, and it's the new default in `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.LogisticRegression(penalty = 'none', fit_intercept = False, solver = 'lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(games[['FG_PCT_DIFF']], games['WON'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the optimal theta (here there's just one, because our model only has one feature) found via `scikit-learn` is the same that we found manually before. (Small deviations due to numerical precision issues.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_theta_mce_nba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` has a built-in `.predict_proba` method that allows us to get the predicted probabilities under our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba([[0.1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is saying that if `FG_PCT_DIFF = 0.1`, that is, if you shoot 10% better than your opponent, there is a 95.5% chance you will win.\n",
    "\n",
    "We can also apply this to our entire training set at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(games[['FG_PCT_DIFF']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(games[['FG_PCT_DIFF']])[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are the same as we computed manually above, as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_probabilities(games['FG_PCT_DIFF'], best_theta_mce_nba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Classifications\n",
    "\n",
    "`scikit-learn` also has an in-built `.predict` method. Let's see what it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(games[['FG_PCT_DIFF']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did it come up with these 1s and 0s?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
